{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:17:05.432265: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 0s - loss: 0.8814 - accuracy: 0.7255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:18:36.595650: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61830, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00859_beta1_0.9025_beta2_0.9925_epochs_5_batch_128.h5\n",
      "391/391 [==============================] - 100s 245ms/step - loss: 0.8814 - accuracy: 0.7255 - val_loss: 1.3810 - val_accuracy: 0.6183\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4896 - accuracy: 0.8502\n",
      "Epoch 2: val_accuracy improved from 0.61830 to 0.81490, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00859_beta1_0.9025_beta2_0.9925_epochs_5_batch_128.h5\n",
      "391/391 [==============================] - 87s 223ms/step - loss: 0.4896 - accuracy: 0.8502 - val_loss: 0.6079 - val_accuracy: 0.8149\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3714 - accuracy: 0.8870\n",
      "Epoch 3: val_accuracy did not improve from 0.81490\n",
      "391/391 [==============================] - 88s 225ms/step - loss: 0.3714 - accuracy: 0.8870 - val_loss: 0.6829 - val_accuracy: 0.8014\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.9106\n",
      "Epoch 4: val_accuracy did not improve from 0.81490\n",
      "391/391 [==============================] - 89s 226ms/step - loss: 0.2895 - accuracy: 0.9106 - val_loss: 0.6791 - val_accuracy: 0.7996\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.9279\n",
      "Epoch 5: val_accuracy did not improve from 0.81490\n",
      "391/391 [==============================] - 88s 226ms/step - loss: 0.2308 - accuracy: 0.9279 - val_loss: 0.7022 - val_accuracy: 0.7986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:24:40.509582: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 1.1367 - accuracy: 0.6265"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:26:56.837623: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71410, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00062_beta1_0.9495_beta2_0.9989_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 147s 90ms/step - loss: 1.1367 - accuracy: 0.6265 - val_loss: 0.9075 - val_accuracy: 0.7141\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6870 - accuracy: 0.7819\n",
      "Epoch 2: val_accuracy improved from 0.71410 to 0.72160, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00062_beta1_0.9495_beta2_0.9989_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 0.6870 - accuracy: 0.7819 - val_loss: 0.8397 - val_accuracy: 0.7216\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.8293\n",
      "Epoch 3: val_accuracy improved from 0.72160 to 0.75970, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00062_beta1_0.9495_beta2_0.9989_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 127s 81ms/step - loss: 0.5381 - accuracy: 0.8293 - val_loss: 0.7581 - val_accuracy: 0.7597\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.8613\n",
      "Epoch 4: val_accuracy improved from 0.75970 to 0.80150, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00062_beta1_0.9495_beta2_0.9989_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 0.4370 - accuracy: 0.8613 - val_loss: 0.5946 - val_accuracy: 0.8015\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3552 - accuracy: 0.8870\n",
      "Epoch 5: val_accuracy improved from 0.80150 to 0.81750, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00062_beta1_0.9495_beta2_0.9989_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 134s 85ms/step - loss: 0.3552 - accuracy: 0.8870 - val_loss: 0.5712 - val_accuracy: 0.8175\n",
      "Epoch 6/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.9059\n",
      "Epoch 6: val_accuracy improved from 0.81750 to 0.86900, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00062_beta1_0.9495_beta2_0.9989_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 130s 83ms/step - loss: 0.2954 - accuracy: 0.9059 - val_loss: 0.4082 - val_accuracy: 0.8690\n",
      "Epoch 7/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2504 - accuracy: 0.9199\n",
      "Epoch 7: val_accuracy did not improve from 0.86900\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 0.2504 - accuracy: 0.9199 - val_loss: 0.4017 - val_accuracy: 0.8688\n",
      "Epoch 8/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.9381\n",
      "Epoch 8: val_accuracy improved from 0.86900 to 0.88190, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00062_beta1_0.9495_beta2_0.9989_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 127s 82ms/step - loss: 0.1972 - accuracy: 0.9381 - val_loss: 0.3851 - val_accuracy: 0.8819\n",
      "Epoch 9/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.9469\n",
      "Epoch 9: val_accuracy did not improve from 0.88190\n",
      "1563/1563 [==============================] - 126s 81ms/step - loss: 0.1648 - accuracy: 0.9469 - val_loss: 0.3928 - val_accuracy: 0.8777\n",
      "Epoch 10/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9545\n",
      "Epoch 10: val_accuracy did not improve from 0.88190\n",
      "1563/1563 [==============================] - 126s 80ms/step - loss: 0.1399 - accuracy: 0.9545 - val_loss: 0.4022 - val_accuracy: 0.8784\n",
      "Epoch 11/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9614\n",
      "Epoch 11: val_accuracy did not improve from 0.88190\n",
      "1563/1563 [==============================] - 126s 80ms/step - loss: 0.1219 - accuracy: 0.9614 - val_loss: 0.4090 - val_accuracy: 0.8808\n",
      "Epoch 12/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9667\n",
      "Epoch 12: val_accuracy did not improve from 0.88190\n",
      "1563/1563 [==============================] - 125s 80ms/step - loss: 0.1052 - accuracy: 0.9667 - val_loss: 0.4276 - val_accuracy: 0.8735\n",
      "Epoch 13/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9700\n",
      "Epoch 13: val_accuracy did not improve from 0.88190\n",
      "1563/1563 [==============================] - 127s 81ms/step - loss: 0.0919 - accuracy: 0.9700 - val_loss: 0.4516 - val_accuracy: 0.8733\n",
      "Epoch 13: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:52:39.699215: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 2.1534 - accuracy: 0.1666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 16:54:49.484252: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.26660, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00464_beta1_0.922_beta2_0.9924_epochs_10_batch_32.h5\n",
      "1563/1563 [==============================] - 140s 86ms/step - loss: 2.1534 - accuracy: 0.1666 - val_loss: 4.0991 - val_accuracy: 0.2666\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.7858 - accuracy: 0.3097\n",
      "Epoch 2: val_accuracy improved from 0.26660 to 0.39800, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00464_beta1_0.922_beta2_0.9924_epochs_10_batch_32.h5\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 1.7858 - accuracy: 0.3097 - val_loss: 2.2055 - val_accuracy: 0.3980\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.4277 - accuracy: 0.4663\n",
      "Epoch 3: val_accuracy improved from 0.39800 to 0.47040, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00464_beta1_0.922_beta2_0.9924_epochs_10_batch_32.h5\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 1.4277 - accuracy: 0.4663 - val_loss: 1.5050 - val_accuracy: 0.4704\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.1708 - accuracy: 0.5924\n",
      "Epoch 4: val_accuracy improved from 0.47040 to 0.61840, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00464_beta1_0.922_beta2_0.9924_epochs_10_batch_32.h5\n",
      "1563/1563 [==============================] - 127s 81ms/step - loss: 1.1708 - accuracy: 0.5924 - val_loss: 1.1092 - val_accuracy: 0.6184\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.9620 - accuracy: 0.6706\n",
      "Epoch 5: val_accuracy improved from 0.61840 to 0.69040, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00464_beta1_0.922_beta2_0.9924_epochs_10_batch_32.h5\n",
      "1563/1563 [==============================] - 127s 82ms/step - loss: 0.9620 - accuracy: 0.6706 - val_loss: 0.8911 - val_accuracy: 0.6904\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8115 - accuracy: 0.7252\n",
      "Epoch 6: val_accuracy did not improve from 0.69040\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 0.8115 - accuracy: 0.7252 - val_loss: 0.9224 - val_accuracy: 0.6901\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.7675\n",
      "Epoch 7: val_accuracy improved from 0.69040 to 0.76810, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00464_beta1_0.922_beta2_0.9924_epochs_10_batch_32.h5\n",
      "1563/1563 [==============================] - 127s 82ms/step - loss: 0.6924 - accuracy: 0.7675 - val_loss: 0.6927 - val_accuracy: 0.7681\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5914 - accuracy: 0.8012\n",
      "Epoch 8: val_accuracy did not improve from 0.76810\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 0.5914 - accuracy: 0.8012 - val_loss: 0.8038 - val_accuracy: 0.7347\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5160 - accuracy: 0.8286\n",
      "Epoch 9: val_accuracy improved from 0.76810 to 0.81800, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00464_beta1_0.922_beta2_0.9924_epochs_10_batch_32.h5\n",
      "1563/1563 [==============================] - 129s 82ms/step - loss: 0.5160 - accuracy: 0.8286 - val_loss: 0.5539 - val_accuracy: 0.8180\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4625 - accuracy: 0.8487\n",
      "Epoch 10: val_accuracy did not improve from 0.81800\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.4625 - accuracy: 0.8487 - val_loss: 0.6258 - val_accuracy: 0.7978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:14:16.665602: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 1.3751 - accuracy: 0.5252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:16:24.683149: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60530, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00781_beta1_0.9115_beta2_0.9956_epochs_5_batch_32.h5\n",
      "1563/1563 [==============================] - 139s 85ms/step - loss: 1.3751 - accuracy: 0.5252 - val_loss: 1.2562 - val_accuracy: 0.6053\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7626 - accuracy: 0.7542\n",
      "Epoch 2: val_accuracy improved from 0.60530 to 0.70660, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00781_beta1_0.9115_beta2_0.9956_epochs_5_batch_32.h5\n",
      "1563/1563 [==============================] - 129s 83ms/step - loss: 0.7626 - accuracy: 0.7542 - val_loss: 1.0134 - val_accuracy: 0.7066\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.8222\n",
      "Epoch 3: val_accuracy improved from 0.70660 to 0.82850, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00781_beta1_0.9115_beta2_0.9956_epochs_5_batch_32.h5\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 0.5566 - accuracy: 0.8222 - val_loss: 0.5250 - val_accuracy: 0.8285\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4351 - accuracy: 0.8627\n",
      "Epoch 4: val_accuracy improved from 0.82850 to 0.84520, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00781_beta1_0.9115_beta2_0.9956_epochs_5_batch_32.h5\n",
      "1563/1563 [==============================] - 127s 82ms/step - loss: 0.4351 - accuracy: 0.8627 - val_loss: 0.4642 - val_accuracy: 0.8452\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.8870\n",
      "Epoch 5: val_accuracy improved from 0.84520 to 0.86530, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00781_beta1_0.9115_beta2_0.9956_epochs_5_batch_32.h5\n",
      "1563/1563 [==============================] - 129s 83ms/step - loss: 0.3518 - accuracy: 0.8870 - val_loss: 0.4080 - val_accuracy: 0.8653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:25:11.460222: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 0s - loss: 0.9579 - accuracy: 0.6935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:26:37.055825: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70430, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00723_beta1_0.9435_beta2_0.994_epochs_15_batch_128.h5\n",
      "391/391 [==============================] - 96s 230ms/step - loss: 0.9579 - accuracy: 0.6935 - val_loss: 0.9496 - val_accuracy: 0.7043\n",
      "Epoch 2/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.8446\n",
      "Epoch 2: val_accuracy improved from 0.70430 to 0.79540, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00723_beta1_0.9435_beta2_0.994_epochs_15_batch_128.h5\n",
      "391/391 [==============================] - 85s 216ms/step - loss: 0.5030 - accuracy: 0.8446 - val_loss: 0.6435 - val_accuracy: 0.7954\n",
      "Epoch 3/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.8830\n",
      "Epoch 3: val_accuracy did not improve from 0.79540\n",
      "391/391 [==============================] - 88s 226ms/step - loss: 0.3766 - accuracy: 0.8830 - val_loss: 0.6739 - val_accuracy: 0.7938\n",
      "Epoch 4/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.9054\n",
      "Epoch 4: val_accuracy improved from 0.79540 to 0.83540, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00723_beta1_0.9435_beta2_0.994_epochs_15_batch_128.h5\n",
      "391/391 [==============================] - 90s 231ms/step - loss: 0.3033 - accuracy: 0.9054 - val_loss: 0.5460 - val_accuracy: 0.8354\n",
      "Epoch 5/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.9244\n",
      "Epoch 5: val_accuracy did not improve from 0.83540\n",
      "391/391 [==============================] - 89s 228ms/step - loss: 0.2425 - accuracy: 0.9244 - val_loss: 0.5717 - val_accuracy: 0.8296\n",
      "Epoch 6/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9372\n",
      "Epoch 6: val_accuracy did not improve from 0.83540\n",
      "391/391 [==============================] - 89s 227ms/step - loss: 0.1999 - accuracy: 0.9372 - val_loss: 0.5672 - val_accuracy: 0.8282\n",
      "Epoch 7/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.9488\n",
      "Epoch 7: val_accuracy improved from 0.83540 to 0.83980, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00723_beta1_0.9435_beta2_0.994_epochs_15_batch_128.h5\n",
      "391/391 [==============================] - 89s 227ms/step - loss: 0.1639 - accuracy: 0.9488 - val_loss: 0.5870 - val_accuracy: 0.8398\n",
      "Epoch 8/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.9569\n",
      "Epoch 8: val_accuracy improved from 0.83980 to 0.84130, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00723_beta1_0.9435_beta2_0.994_epochs_15_batch_128.h5\n",
      "391/391 [==============================] - 89s 227ms/step - loss: 0.1377 - accuracy: 0.9569 - val_loss: 0.5654 - val_accuracy: 0.8413\n",
      "Epoch 9/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9630\n",
      "Epoch 9: val_accuracy improved from 0.84130 to 0.88060, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00723_beta1_0.9435_beta2_0.994_epochs_15_batch_128.h5\n",
      "391/391 [==============================] - 89s 227ms/step - loss: 0.1200 - accuracy: 0.9630 - val_loss: 0.4301 - val_accuracy: 0.8806\n",
      "Epoch 10/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9686\n",
      "Epoch 10: val_accuracy did not improve from 0.88060\n",
      "391/391 [==============================] - 88s 226ms/step - loss: 0.0998 - accuracy: 0.9686 - val_loss: 0.4325 - val_accuracy: 0.8777\n",
      "Epoch 11/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9718\n",
      "Epoch 11: val_accuracy did not improve from 0.88060\n",
      "391/391 [==============================] - 88s 226ms/step - loss: 0.0888 - accuracy: 0.9718 - val_loss: 0.5748 - val_accuracy: 0.8558\n",
      "Epoch 12/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9741\n",
      "Epoch 12: val_accuracy did not improve from 0.88060\n",
      "391/391 [==============================] - 88s 226ms/step - loss: 0.0831 - accuracy: 0.9741 - val_loss: 0.5064 - val_accuracy: 0.8656\n",
      "Epoch 13/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9776\n",
      "Epoch 13: val_accuracy did not improve from 0.88060\n",
      "391/391 [==============================] - 88s 226ms/step - loss: 0.0690 - accuracy: 0.9776 - val_loss: 0.5142 - val_accuracy: 0.8717\n",
      "Epoch 14/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9787\n",
      "Epoch 14: val_accuracy did not improve from 0.88060\n",
      "391/391 [==============================] - 89s 228ms/step - loss: 0.0673 - accuracy: 0.9787 - val_loss: 0.5966 - val_accuracy: 0.8595\n",
      "Epoch 14: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:45:58.570757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 1.2509 - accuracy: 0.5807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 17:48:10.402760: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66760, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 144s 88ms/step - loss: 1.2509 - accuracy: 0.5807 - val_loss: 0.9490 - val_accuracy: 0.6676\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6910 - accuracy: 0.7791\n",
      "Epoch 2: val_accuracy improved from 0.66760 to 0.74410, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.6910 - accuracy: 0.7791 - val_loss: 0.8291 - val_accuracy: 0.7441\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5098 - accuracy: 0.8360\n",
      "Epoch 3: val_accuracy improved from 0.74410 to 0.84280, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.5098 - accuracy: 0.8360 - val_loss: 0.4819 - val_accuracy: 0.8428\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8703\n",
      "Epoch 4: val_accuracy improved from 0.84280 to 0.85150, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.4030 - accuracy: 0.8703 - val_loss: 0.4461 - val_accuracy: 0.8515\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.8983\n",
      "Epoch 5: val_accuracy improved from 0.85150 to 0.85910, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.3177 - accuracy: 0.8983 - val_loss: 0.4338 - val_accuracy: 0.8591\n",
      "Epoch 6/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.9161\n",
      "Epoch 6: val_accuracy did not improve from 0.85910\n",
      "1563/1563 [==============================] - 132s 85ms/step - loss: 0.2591 - accuracy: 0.9161 - val_loss: 0.4333 - val_accuracy: 0.8590\n",
      "Epoch 7/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2110 - accuracy: 0.9316\n",
      "Epoch 7: val_accuracy improved from 0.85910 to 0.86160, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.2110 - accuracy: 0.9316 - val_loss: 0.4178 - val_accuracy: 0.8616\n",
      "Epoch 8/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1674 - accuracy: 0.9457\n",
      "Epoch 8: val_accuracy improved from 0.86160 to 0.86380, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.1674 - accuracy: 0.9457 - val_loss: 0.4382 - val_accuracy: 0.8638\n",
      "Epoch 9/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.9520\n",
      "Epoch 9: val_accuracy improved from 0.86380 to 0.89150, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_32.h5\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.1508 - accuracy: 0.9520 - val_loss: 0.3501 - val_accuracy: 0.8915\n",
      "Epoch 10/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9599\n",
      "Epoch 10: val_accuracy did not improve from 0.89150\n",
      "1563/1563 [==============================] - 130s 83ms/step - loss: 0.1252 - accuracy: 0.9599 - val_loss: 0.3976 - val_accuracy: 0.8800\n",
      "Epoch 11/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9652\n",
      "Epoch 11: val_accuracy did not improve from 0.89150\n",
      "1563/1563 [==============================] - 129s 83ms/step - loss: 0.1096 - accuracy: 0.9652 - val_loss: 0.5310 - val_accuracy: 0.8498\n",
      "Epoch 12/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9700\n",
      "Epoch 12: val_accuracy did not improve from 0.89150\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 0.0938 - accuracy: 0.9700 - val_loss: 0.4050 - val_accuracy: 0.8899\n",
      "Epoch 13/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.9727\n",
      "Epoch 13: val_accuracy did not improve from 0.89150\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 0.0862 - accuracy: 0.9727 - val_loss: 0.3951 - val_accuracy: 0.8849\n",
      "Epoch 14/15\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9749\n",
      "Epoch 14: val_accuracy did not improve from 0.89150\n",
      "1563/1563 [==============================] - 129s 82ms/step - loss: 0.0808 - accuracy: 0.9749 - val_loss: 0.4588 - val_accuracy: 0.8793\n",
      "Epoch 14: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:16:41.902569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 0.9826 - accuracy: 0.6953"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:18:18.608478: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61360, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00657_beta1_0.8759_beta2_0.9911_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 106s 125ms/step - loss: 0.9826 - accuracy: 0.6953 - val_loss: 1.5056 - val_accuracy: 0.6136\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.5712 - accuracy: 0.8209\n",
      "Epoch 2: val_accuracy improved from 0.61360 to 0.77820, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00657_beta1_0.8759_beta2_0.9911_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 92s 117ms/step - loss: 0.5712 - accuracy: 0.8209 - val_loss: 0.6883 - val_accuracy: 0.7782\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.8687\n",
      "Epoch 3: val_accuracy improved from 0.77820 to 0.82470, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00657_beta1_0.8759_beta2_0.9911_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 93s 119ms/step - loss: 0.4164 - accuracy: 0.8687 - val_loss: 0.5593 - val_accuracy: 0.8247\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.8974\n",
      "Epoch 4: val_accuracy did not improve from 0.82470\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.3230 - accuracy: 0.8974 - val_loss: 0.6254 - val_accuracy: 0.8056\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2539 - accuracy: 0.9192\n",
      "Epoch 5: val_accuracy improved from 0.82470 to 0.82590, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00657_beta1_0.8759_beta2_0.9911_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 0.2539 - accuracy: 0.9192 - val_loss: 0.5710 - val_accuracy: 0.8259\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2034 - accuracy: 0.9346\n",
      "Epoch 6: val_accuracy improved from 0.82590 to 0.83770, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00657_beta1_0.8759_beta2_0.9911_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.2034 - accuracy: 0.9346 - val_loss: 0.5312 - val_accuracy: 0.8377\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9464\n",
      "Epoch 7: val_accuracy improved from 0.83770 to 0.88960, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00657_beta1_0.8759_beta2_0.9911_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.1659 - accuracy: 0.9464 - val_loss: 0.3518 - val_accuracy: 0.8896\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.9573\n",
      "Epoch 8: val_accuracy did not improve from 0.88960\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.1373 - accuracy: 0.9573 - val_loss: 0.4227 - val_accuracy: 0.8738\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.9613\n",
      "Epoch 9: val_accuracy improved from 0.88960 to 0.89040, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00657_beta1_0.8759_beta2_0.9911_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.1199 - accuracy: 0.9613 - val_loss: 0.3663 - val_accuracy: 0.8904\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9677\n",
      "Epoch 10: val_accuracy improved from 0.89040 to 0.89140, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00657_beta1_0.8759_beta2_0.9911_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.1011 - accuracy: 0.9677 - val_loss: 0.3758 - val_accuracy: 0.8914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:32:39.409658: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 1.5481 - accuracy: 0.4279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:34:19.285341: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52180, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00667_beta1_0.8783_beta2_0.9909_epochs_5_batch_64.h5\n",
      "782/782 [==============================] - 110s 130ms/step - loss: 1.5481 - accuracy: 0.4279 - val_loss: 1.6199 - val_accuracy: 0.5218\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.7692 - accuracy: 0.7527\n",
      "Epoch 2: val_accuracy improved from 0.52180 to 0.77440, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00667_beta1_0.8783_beta2_0.9909_epochs_5_batch_64.h5\n",
      "782/782 [==============================] - 92s 118ms/step - loss: 0.7692 - accuracy: 0.7527 - val_loss: 0.6965 - val_accuracy: 0.7744\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.5277 - accuracy: 0.8327\n",
      "Epoch 3: val_accuracy did not improve from 0.77440\n",
      "782/782 [==============================] - 93s 119ms/step - loss: 0.5277 - accuracy: 0.8327 - val_loss: 0.7949 - val_accuracy: 0.7633\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.8712\n",
      "Epoch 4: val_accuracy improved from 0.77440 to 0.85650, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00667_beta1_0.8783_beta2_0.9909_epochs_5_batch_64.h5\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.4074 - accuracy: 0.8712 - val_loss: 0.4439 - val_accuracy: 0.8565\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3174 - accuracy: 0.8992\n",
      "Epoch 5: val_accuracy did not improve from 0.85650\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.3174 - accuracy: 0.8992 - val_loss: 1.1027 - val_accuracy: 0.7062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:40:45.742493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 0.9895 - accuracy: 0.6899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 18:42:25.989970: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60460, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00663_beta1_0.8746_beta2_0.9937_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 111s 133ms/step - loss: 0.9895 - accuracy: 0.6899 - val_loss: 1.5384 - val_accuracy: 0.6046\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.5747 - accuracy: 0.8203\n",
      "Epoch 2: val_accuracy improved from 0.60460 to 0.69870, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00663_beta1_0.8746_beta2_0.9937_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 92s 118ms/step - loss: 0.5747 - accuracy: 0.8203 - val_loss: 0.9808 - val_accuracy: 0.6987\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.4293 - accuracy: 0.8652\n",
      "Epoch 3: val_accuracy improved from 0.69870 to 0.83360, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00663_beta1_0.8746_beta2_0.9937_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.4293 - accuracy: 0.8652 - val_loss: 0.5038 - val_accuracy: 0.8336\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.8940\n",
      "Epoch 4: val_accuracy improved from 0.83360 to 0.84670, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00663_beta1_0.8746_beta2_0.9937_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.3366 - accuracy: 0.8940 - val_loss: 0.4820 - val_accuracy: 0.8467\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.9156\n",
      "Epoch 5: val_accuracy improved from 0.84670 to 0.86040, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00663_beta1_0.8746_beta2_0.9937_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.2671 - accuracy: 0.9156 - val_loss: 0.4424 - val_accuracy: 0.8604\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2126 - accuracy: 0.9310\n",
      "Epoch 6: val_accuracy did not improve from 0.86040\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.2126 - accuracy: 0.9310 - val_loss: 0.5760 - val_accuracy: 0.8195\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9432\n",
      "Epoch 7: val_accuracy improved from 0.86040 to 0.86910, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00663_beta1_0.8746_beta2_0.9937_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.1765 - accuracy: 0.9432 - val_loss: 0.4510 - val_accuracy: 0.8691\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.9534\n",
      "Epoch 8: val_accuracy did not improve from 0.86910\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.1463 - accuracy: 0.9534 - val_loss: 0.5519 - val_accuracy: 0.8404\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.9617\n",
      "Epoch 9: val_accuracy improved from 0.86910 to 0.88820, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00663_beta1_0.8746_beta2_0.9937_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.1208 - accuracy: 0.9617 - val_loss: 0.3802 - val_accuracy: 0.8882\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9664\n",
      "Epoch 10: val_accuracy did not improve from 0.88820\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.1054 - accuracy: 0.9664 - val_loss: 0.3874 - val_accuracy: 0.8862\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9685\n",
      "Epoch 11: val_accuracy improved from 0.88820 to 0.89440, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00663_beta1_0.8746_beta2_0.9937_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.0976 - accuracy: 0.9685 - val_loss: 0.3835 - val_accuracy: 0.8944\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9730\n",
      "Epoch 12: val_accuracy did not improve from 0.89440\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.0841 - accuracy: 0.9730 - val_loss: 0.4521 - val_accuracy: 0.8774\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9769\n",
      "Epoch 13: val_accuracy improved from 0.89440 to 0.89920, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00663_beta1_0.8746_beta2_0.9937_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.0714 - accuracy: 0.9769 - val_loss: 0.3605 - val_accuracy: 0.8992\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9776\n",
      "Epoch 14: val_accuracy did not improve from 0.89920\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.0694 - accuracy: 0.9776 - val_loss: 0.4104 - val_accuracy: 0.8899\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9792\n",
      "Epoch 15: val_accuracy did not improve from 0.89920\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.0656 - accuracy: 0.9792 - val_loss: 0.3860 - val_accuracy: 0.8962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:04:34.148256: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 1.6043 - accuracy: 0.4190"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:06:12.760875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55660, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.95_beta2_0.999_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 111s 133ms/step - loss: 1.6043 - accuracy: 0.4190 - val_loss: 1.5463 - val_accuracy: 0.5566\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.7501 - accuracy: 0.7627\n",
      "Epoch 2: val_accuracy improved from 0.55660 to 0.71340, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.95_beta2_0.999_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 92s 117ms/step - loss: 0.7501 - accuracy: 0.7627 - val_loss: 0.9024 - val_accuracy: 0.7134\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.8348\n",
      "Epoch 3: val_accuracy improved from 0.71340 to 0.80640, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.95_beta2_0.999_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 93s 119ms/step - loss: 0.5273 - accuracy: 0.8348 - val_loss: 0.6138 - val_accuracy: 0.8064\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.4195 - accuracy: 0.8697\n",
      "Epoch 4: val_accuracy did not improve from 0.80640\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.4195 - accuracy: 0.8697 - val_loss: 1.0150 - val_accuracy: 0.6884\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3373 - accuracy: 0.8942\n",
      "Epoch 5: val_accuracy improved from 0.80640 to 0.86870, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.95_beta2_0.999_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.3373 - accuracy: 0.8942 - val_loss: 0.4177 - val_accuracy: 0.8687\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2846 - accuracy: 0.9095\n",
      "Epoch 6: val_accuracy did not improve from 0.86870\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.2846 - accuracy: 0.9095 - val_loss: 0.8293 - val_accuracy: 0.7647\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2426 - accuracy: 0.9223\n",
      "Epoch 7: val_accuracy did not improve from 0.86870\n",
      "782/782 [==============================] - 93s 119ms/step - loss: 0.2426 - accuracy: 0.9223 - val_loss: 0.4210 - val_accuracy: 0.8673\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9378\n",
      "Epoch 8: val_accuracy improved from 0.86870 to 0.87540, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.95_beta2_0.999_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.2016 - accuracy: 0.9378 - val_loss: 0.4081 - val_accuracy: 0.8754\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9471\n",
      "Epoch 9: val_accuracy did not improve from 0.87540\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.1676 - accuracy: 0.9471 - val_loss: 0.4339 - val_accuracy: 0.8725\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9554\n",
      "Epoch 10: val_accuracy did not improve from 0.87540\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.1421 - accuracy: 0.9554 - val_loss: 0.4510 - val_accuracy: 0.8733\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.9589\n",
      "Epoch 11: val_accuracy did not improve from 0.87540\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.1308 - accuracy: 0.9589 - val_loss: 0.5367 - val_accuracy: 0.8560\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9635\n",
      "Epoch 12: val_accuracy improved from 0.87540 to 0.87570, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.95_beta2_0.999_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.1159 - accuracy: 0.9635 - val_loss: 0.4338 - val_accuracy: 0.8757\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9701\n",
      "Epoch 13: val_accuracy did not improve from 0.87570\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.0946 - accuracy: 0.9701 - val_loss: 0.4737 - val_accuracy: 0.8713\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9739\n",
      "Epoch 14: val_accuracy did not improve from 0.87570\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.0867 - accuracy: 0.9739 - val_loss: 0.4559 - val_accuracy: 0.8748\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9749\n",
      "Epoch 15: val_accuracy did not improve from 0.87570\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.0798 - accuracy: 0.9749 - val_loss: 0.5112 - val_accuracy: 0.8583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:28:19.430228: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 1.0085 - accuracy: 0.6810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:29:56.797455: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.44080, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.008_beta1_0.8596_beta2_0.9903_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 108s 128ms/step - loss: 1.0085 - accuracy: 0.6810 - val_loss: 3.1237 - val_accuracy: 0.4408\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.8227\n",
      "Epoch 2: val_accuracy improved from 0.44080 to 0.78150, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.008_beta1_0.8596_beta2_0.9903_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 92s 118ms/step - loss: 0.5683 - accuracy: 0.8227 - val_loss: 0.6864 - val_accuracy: 0.7815\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.4185 - accuracy: 0.8675\n",
      "Epoch 3: val_accuracy improved from 0.78150 to 0.81500, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.008_beta1_0.8596_beta2_0.9903_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 93s 119ms/step - loss: 0.4185 - accuracy: 0.8675 - val_loss: 0.5610 - val_accuracy: 0.8150\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.8973\n",
      "Epoch 4: val_accuracy improved from 0.81500 to 0.85360, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.008_beta1_0.8596_beta2_0.9903_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.3210 - accuracy: 0.8973 - val_loss: 0.4460 - val_accuracy: 0.8536\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2534 - accuracy: 0.9184\n",
      "Epoch 5: val_accuracy did not improve from 0.85360\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.2534 - accuracy: 0.9184 - val_loss: 0.4908 - val_accuracy: 0.8515\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2101 - accuracy: 0.9336\n",
      "Epoch 6: val_accuracy improved from 0.85360 to 0.86250, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.008_beta1_0.8596_beta2_0.9903_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.2101 - accuracy: 0.9336 - val_loss: 0.4318 - val_accuracy: 0.8625\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.9464\n",
      "Epoch 7: val_accuracy did not improve from 0.86250\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.1707 - accuracy: 0.9464 - val_loss: 0.4754 - val_accuracy: 0.8582\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1459 - accuracy: 0.9539\n",
      "Epoch 8: val_accuracy improved from 0.86250 to 0.89450, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.008_beta1_0.8596_beta2_0.9903_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.1459 - accuracy: 0.9539 - val_loss: 0.3487 - val_accuracy: 0.8945\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.9609\n",
      "Epoch 9: val_accuracy did not improve from 0.89450\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.1222 - accuracy: 0.9609 - val_loss: 0.3913 - val_accuracy: 0.8843\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.9690\n",
      "Epoch 10: val_accuracy did not improve from 0.89450\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.1020 - accuracy: 0.9690 - val_loss: 0.4137 - val_accuracy: 0.8868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:44:14.320391: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 0.9357 - accuracy: 0.7066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 19:45:55.772280: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41950, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 112s 134ms/step - loss: 0.9357 - accuracy: 0.7066 - val_loss: 2.5131 - val_accuracy: 0.4195\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.5721 - accuracy: 0.8223\n",
      "Epoch 2: val_accuracy improved from 0.41950 to 0.70620, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 93s 119ms/step - loss: 0.5721 - accuracy: 0.8223 - val_loss: 0.9568 - val_accuracy: 0.7062\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.8696\n",
      "Epoch 3: val_accuracy improved from 0.70620 to 0.78430, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 93s 119ms/step - loss: 0.4130 - accuracy: 0.8696 - val_loss: 0.6728 - val_accuracy: 0.7843\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.8986\n",
      "Epoch 4: val_accuracy improved from 0.78430 to 0.85810, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.3169 - accuracy: 0.8986 - val_loss: 0.4300 - val_accuracy: 0.8581\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2544 - accuracy: 0.9201\n",
      "Epoch 5: val_accuracy did not improve from 0.85810\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.2544 - accuracy: 0.9201 - val_loss: 0.5327 - val_accuracy: 0.8348\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.9342\n",
      "Epoch 6: val_accuracy did not improve from 0.85810\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 0.2064 - accuracy: 0.9342 - val_loss: 0.5933 - val_accuracy: 0.8315\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9460\n",
      "Epoch 7: val_accuracy improved from 0.85810 to 0.88620, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 0.1697 - accuracy: 0.9460 - val_loss: 0.3667 - val_accuracy: 0.8862\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 0.9561\n",
      "Epoch 8: val_accuracy improved from 0.88620 to 0.89550, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 0.1391 - accuracy: 0.9561 - val_loss: 0.3444 - val_accuracy: 0.8955\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.9624\n",
      "Epoch 9: val_accuracy improved from 0.89550 to 0.89560, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.1198 - accuracy: 0.9624 - val_loss: 0.3502 - val_accuracy: 0.8956\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9680\n",
      "Epoch 10: val_accuracy did not improve from 0.89560\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.1025 - accuracy: 0.9680 - val_loss: 0.4395 - val_accuracy: 0.8796\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9717\n",
      "Epoch 11: val_accuracy did not improve from 0.89560\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.0903 - accuracy: 0.9717 - val_loss: 0.3765 - val_accuracy: 0.8956\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9745\n",
      "Epoch 12: val_accuracy did not improve from 0.89560\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.0792 - accuracy: 0.9745 - val_loss: 0.4473 - val_accuracy: 0.8824\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9774\n",
      "Epoch 13: val_accuracy did not improve from 0.89560\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.0714 - accuracy: 0.9774 - val_loss: 0.4050 - val_accuracy: 0.8918\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9790\n",
      "Epoch 14: val_accuracy did not improve from 0.89560\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.0659 - accuracy: 0.9790 - val_loss: 0.4595 - val_accuracy: 0.8812\n",
      "Epoch 14: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:06:41.806026: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 0s - loss: 0.9388 - accuracy: 0.7080"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:08:14.431838: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57050, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00755_beta1_0.9334_beta2_0.9901_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 104s 250ms/step - loss: 0.9388 - accuracy: 0.7080 - val_loss: 1.7837 - val_accuracy: 0.5705\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5111 - accuracy: 0.8443\n",
      "Epoch 2: val_accuracy improved from 0.57050 to 0.72230, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00755_beta1_0.9334_beta2_0.9901_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 86s 221ms/step - loss: 0.5111 - accuracy: 0.8443 - val_loss: 1.0229 - val_accuracy: 0.7223\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8836\n",
      "Epoch 3: val_accuracy improved from 0.72230 to 0.83650, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00755_beta1_0.9334_beta2_0.9901_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 88s 224ms/step - loss: 0.3779 - accuracy: 0.8836 - val_loss: 0.5480 - val_accuracy: 0.8365\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2977 - accuracy: 0.9076\n",
      "Epoch 4: val_accuracy did not improve from 0.83650\n",
      "391/391 [==============================] - 89s 227ms/step - loss: 0.2977 - accuracy: 0.9076 - val_loss: 0.6911 - val_accuracy: 0.8092\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.9273\n",
      "Epoch 5: val_accuracy did not improve from 0.83650\n",
      "391/391 [==============================] - 89s 227ms/step - loss: 0.2299 - accuracy: 0.9273 - val_loss: 0.5790 - val_accuracy: 0.8354\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.9406\n",
      "Epoch 6: val_accuracy improved from 0.83650 to 0.86940, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00755_beta1_0.9334_beta2_0.9901_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 89s 227ms/step - loss: 0.1899 - accuracy: 0.9406 - val_loss: 0.4356 - val_accuracy: 0.8694\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.9514\n",
      "Epoch 7: val_accuracy did not improve from 0.86940\n",
      "391/391 [==============================] - 88s 226ms/step - loss: 0.1562 - accuracy: 0.9514 - val_loss: 0.4547 - val_accuracy: 0.8690\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9581\n",
      "Epoch 8: val_accuracy improved from 0.86940 to 0.88370, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00755_beta1_0.9334_beta2_0.9901_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 90s 230ms/step - loss: 0.1351 - accuracy: 0.9581 - val_loss: 0.3905 - val_accuracy: 0.8837\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9656\n",
      "Epoch 9: val_accuracy improved from 0.88370 to 0.89620, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.00755_beta1_0.9334_beta2_0.9901_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 89s 229ms/step - loss: 0.1097 - accuracy: 0.9656 - val_loss: 0.3619 - val_accuracy: 0.8962\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9718\n",
      "Epoch 10: val_accuracy did not improve from 0.89620\n",
      "391/391 [==============================] - 89s 227ms/step - loss: 0.0926 - accuracy: 0.9718 - val_loss: 0.4482 - val_accuracy: 0.8801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:21:44.336751: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 0s - loss: 0.8175 - accuracy: 0.7508"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:23:17.795846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70720, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.85_beta2_0.999_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 105s 250ms/step - loss: 0.8175 - accuracy: 0.7508 - val_loss: 1.0012 - val_accuracy: 0.7072\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4119 - accuracy: 0.8754\n",
      "Epoch 2: val_accuracy improved from 0.70720 to 0.77790, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.85_beta2_0.999_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 87s 222ms/step - loss: 0.4119 - accuracy: 0.8754 - val_loss: 0.7429 - val_accuracy: 0.7779\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3000 - accuracy: 0.9094\n",
      "Epoch 3: val_accuracy improved from 0.77790 to 0.80800, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.85_beta2_0.999_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 88s 226ms/step - loss: 0.3000 - accuracy: 0.9094 - val_loss: 0.6591 - val_accuracy: 0.8080\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.9252\n",
      "Epoch 4: val_accuracy did not improve from 0.80800\n",
      "391/391 [==============================] - 89s 228ms/step - loss: 0.2421 - accuracy: 0.9252 - val_loss: 0.6485 - val_accuracy: 0.8030\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.9375\n",
      "Epoch 5: val_accuracy improved from 0.80800 to 0.83140, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.85_beta2_0.999_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 90s 229ms/step - loss: 0.2035 - accuracy: 0.9375 - val_loss: 0.5843 - val_accuracy: 0.8314\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9486\n",
      "Epoch 6: val_accuracy improved from 0.83140 to 0.85500, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.85_beta2_0.999_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 90s 230ms/step - loss: 0.1656 - accuracy: 0.9486 - val_loss: 0.4743 - val_accuracy: 0.8550\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9520\n",
      "Epoch 7: val_accuracy improved from 0.85500 to 0.86170, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.85_beta2_0.999_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 90s 229ms/step - loss: 0.1522 - accuracy: 0.9520 - val_loss: 0.4826 - val_accuracy: 0.8617\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.9595\n",
      "Epoch 8: val_accuracy improved from 0.86170 to 0.87570, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.85_beta2_0.999_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 89s 229ms/step - loss: 0.1293 - accuracy: 0.9595 - val_loss: 0.4429 - val_accuracy: 0.8757\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9667\n",
      "Epoch 9: val_accuracy improved from 0.87570 to 0.87850, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.85_beta2_0.999_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 89s 228ms/step - loss: 0.1093 - accuracy: 0.9667 - val_loss: 0.4250 - val_accuracy: 0.8785\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9689\n",
      "Epoch 10: val_accuracy did not improve from 0.87850\n",
      "391/391 [==============================] - 89s 227ms/step - loss: 0.0996 - accuracy: 0.9689 - val_loss: 0.4704 - val_accuracy: 0.8710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:36:52.213321: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 0s - loss: 0.8398 - accuracy: 0.7390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:38:28.636200: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67940, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.85_beta2_0.999_epochs_15_batch_128.h5\n",
      "391/391 [==============================] - 108s 256ms/step - loss: 0.8398 - accuracy: 0.7390 - val_loss: 1.1785 - val_accuracy: 0.6794\n",
      "Epoch 2/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.8770\n",
      "Epoch 2: val_accuracy improved from 0.67940 to 0.78640, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.85_beta2_0.999_epochs_15_batch_128.h5\n",
      "391/391 [==============================] - 86s 220ms/step - loss: 0.4097 - accuracy: 0.8770 - val_loss: 0.7349 - val_accuracy: 0.7864\n",
      "Epoch 3/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2971 - accuracy: 0.9118\n",
      "Epoch 3: val_accuracy improved from 0.78640 to 0.86400, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.85_beta2_0.999_epochs_15_batch_128.h5\n",
      "391/391 [==============================] - 88s 224ms/step - loss: 0.2971 - accuracy: 0.9118 - val_loss: 0.4415 - val_accuracy: 0.8640\n",
      "Epoch 4/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.9277\n",
      "Epoch 4: val_accuracy did not improve from 0.86400\n",
      "391/391 [==============================] - 89s 228ms/step - loss: 0.2384 - accuracy: 0.9277 - val_loss: 0.4569 - val_accuracy: 0.8605\n",
      "Epoch 5/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9379\n",
      "Epoch 5: val_accuracy did not improve from 0.86400\n",
      "391/391 [==============================] - 89s 228ms/step - loss: 0.2014 - accuracy: 0.9379 - val_loss: 0.8313 - val_accuracy: 0.7777\n",
      "Epoch 6/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1660 - accuracy: 0.9491\n",
      "Epoch 6: val_accuracy did not improve from 0.86400\n",
      "391/391 [==============================] - 89s 228ms/step - loss: 0.1660 - accuracy: 0.9491 - val_loss: 0.6315 - val_accuracy: 0.8315\n",
      "Epoch 7/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1444 - accuracy: 0.9550\n",
      "Epoch 7: val_accuracy did not improve from 0.86400\n",
      "391/391 [==============================] - 89s 228ms/step - loss: 0.1444 - accuracy: 0.9550 - val_loss: 0.6067 - val_accuracy: 0.8328\n",
      "Epoch 8/15\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.9611\n",
      "Epoch 8: val_accuracy did not improve from 0.86400\n",
      "391/391 [==============================] - 89s 228ms/step - loss: 0.1245 - accuracy: 0.9611 - val_loss: 0.6056 - val_accuracy: 0.8337\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:49:01.911115: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 0s - loss: 0.9790 - accuracy: 0.6951"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:50:42.936954: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74220, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.95_beta2_0.999_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 113s 251ms/step - loss: 0.9790 - accuracy: 0.6951 - val_loss: 0.8072 - val_accuracy: 0.7422\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4679 - accuracy: 0.8578\n",
      "Epoch 2: val_accuracy improved from 0.74220 to 0.84050, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.95_beta2_0.999_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 86s 220ms/step - loss: 0.4679 - accuracy: 0.8578 - val_loss: 0.5148 - val_accuracy: 0.8405\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3335 - accuracy: 0.8978\n",
      "Epoch 3: val_accuracy did not improve from 0.84050\n",
      "391/391 [==============================] - 87s 224ms/step - loss: 0.3335 - accuracy: 0.8978 - val_loss: 0.5589 - val_accuracy: 0.8273\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2724 - accuracy: 0.9164\n",
      "Epoch 4: val_accuracy improved from 0.84050 to 0.86600, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.0_beta1_0.95_beta2_0.999_epochs_10_batch_128.h5\n",
      "391/391 [==============================] - 90s 230ms/step - loss: 0.2724 - accuracy: 0.9164 - val_loss: 0.4406 - val_accuracy: 0.8660\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.9332\n",
      "Epoch 5: val_accuracy did not improve from 0.86600\n",
      "391/391 [==============================] - 89s 228ms/step - loss: 0.2194 - accuracy: 0.9332 - val_loss: 0.5648 - val_accuracy: 0.8388\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.9445\n",
      "Epoch 6: val_accuracy did not improve from 0.86600\n",
      "391/391 [==============================] - 88s 225ms/step - loss: 0.1825 - accuracy: 0.9445 - val_loss: 0.5226 - val_accuracy: 0.8532\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1587 - accuracy: 0.9505\n",
      "Epoch 7: val_accuracy did not improve from 0.86600\n",
      "391/391 [==============================] - 88s 226ms/step - loss: 0.1587 - accuracy: 0.9505 - val_loss: 0.4923 - val_accuracy: 0.8608\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9588\n",
      "Epoch 8: val_accuracy did not improve from 0.86600\n",
      "391/391 [==============================] - 88s 225ms/step - loss: 0.1327 - accuracy: 0.9588 - val_loss: 0.8573 - val_accuracy: 0.7923\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.1276 - accuracy: 0.9605\n",
      "Epoch 9: val_accuracy did not improve from 0.86600\n",
      "391/391 [==============================] - 88s 225ms/step - loss: 0.1276 - accuracy: 0.9605 - val_loss: 0.5077 - val_accuracy: 0.8589\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:02:40.990165: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 1.3044 - accuracy: 0.5535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:04:28.088477: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67080, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 121s 141ms/step - loss: 1.3044 - accuracy: 0.5535 - val_loss: 1.0180 - val_accuracy: 0.6708\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.6457 - accuracy: 0.7995\n",
      "Epoch 2: val_accuracy improved from 0.67080 to 0.70570, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.6457 - accuracy: 0.7995 - val_loss: 0.9930 - val_accuracy: 0.7057\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.4672 - accuracy: 0.8521\n",
      "Epoch 3: val_accuracy improved from 0.70570 to 0.76520, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.4672 - accuracy: 0.8521 - val_loss: 0.7561 - val_accuracy: 0.7652\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.8873\n",
      "Epoch 4: val_accuracy improved from 0.76520 to 0.82620, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.3583 - accuracy: 0.8873 - val_loss: 0.5537 - val_accuracy: 0.8262\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2889 - accuracy: 0.9094\n",
      "Epoch 5: val_accuracy improved from 0.82620 to 0.86200, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.2889 - accuracy: 0.9094 - val_loss: 0.4281 - val_accuracy: 0.8620\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.9270\n",
      "Epoch 6: val_accuracy did not improve from 0.86200\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.2296 - accuracy: 0.9270 - val_loss: 0.4862 - val_accuracy: 0.8482\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1895 - accuracy: 0.9402\n",
      "Epoch 7: val_accuracy improved from 0.86200 to 0.87020, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.1895 - accuracy: 0.9402 - val_loss: 0.4185 - val_accuracy: 0.8702\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.9513\n",
      "Epoch 8: val_accuracy did not improve from 0.87020\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.1541 - accuracy: 0.9513 - val_loss: 0.4603 - val_accuracy: 0.8668\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.9584\n",
      "Epoch 9: val_accuracy did not improve from 0.87020\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.1299 - accuracy: 0.9584 - val_loss: 0.5621 - val_accuracy: 0.8447\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9661\n",
      "Epoch 10: val_accuracy improved from 0.87020 to 0.88490, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_10_batch_64.h5\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.1071 - accuracy: 0.9661 - val_loss: 0.4196 - val_accuracy: 0.8849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:18:58.667438: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 0.9793 - accuracy: 0.6878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:20:46.176726: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75010, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 119s 138ms/step - loss: 0.9793 - accuracy: 0.6878 - val_loss: 0.7997 - val_accuracy: 0.7501\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.5562 - accuracy: 0.8255\n",
      "Epoch 2: val_accuracy did not improve from 0.75010\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.5562 - accuracy: 0.8255 - val_loss: 0.8678 - val_accuracy: 0.7440\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.4095 - accuracy: 0.8705\n",
      "Epoch 3: val_accuracy improved from 0.75010 to 0.84980, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.4095 - accuracy: 0.8705 - val_loss: 0.4585 - val_accuracy: 0.8498\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.9006\n",
      "Epoch 4: val_accuracy did not improve from 0.84980\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.3178 - accuracy: 0.9006 - val_loss: 0.6810 - val_accuracy: 0.7903\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.9198\n",
      "Epoch 5: val_accuracy improved from 0.84980 to 0.86940, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 0.2528 - accuracy: 0.9198 - val_loss: 0.4179 - val_accuracy: 0.8694\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2041 - accuracy: 0.9345\n",
      "Epoch 6: val_accuracy improved from 0.86940 to 0.87130, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 96s 123ms/step - loss: 0.2041 - accuracy: 0.9345 - val_loss: 0.4300 - val_accuracy: 0.8713\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.9472\n",
      "Epoch 7: val_accuracy did not improve from 0.87130\n",
      "782/782 [==============================] - 96s 123ms/step - loss: 0.1679 - accuracy: 0.9472 - val_loss: 0.5134 - val_accuracy: 0.8541\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.9550\n",
      "Epoch 8: val_accuracy did not improve from 0.87130\n",
      "782/782 [==============================] - 96s 123ms/step - loss: 0.1422 - accuracy: 0.9550 - val_loss: 0.4908 - val_accuracy: 0.8559\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9624\n",
      "Epoch 9: val_accuracy improved from 0.87130 to 0.87820, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 97s 124ms/step - loss: 0.1181 - accuracy: 0.9624 - val_loss: 0.4248 - val_accuracy: 0.8782\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9669\n",
      "Epoch 10: val_accuracy improved from 0.87820 to 0.88110, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 96s 123ms/step - loss: 0.1030 - accuracy: 0.9669 - val_loss: 0.4232 - val_accuracy: 0.8811\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.9707\n",
      "Epoch 11: val_accuracy improved from 0.88110 to 0.88780, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.0936 - accuracy: 0.9707 - val_loss: 0.3825 - val_accuracy: 0.8878\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9742\n",
      "Epoch 12: val_accuracy did not improve from 0.88780\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.0805 - accuracy: 0.9742 - val_loss: 0.4388 - val_accuracy: 0.8819\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9775\n",
      "Epoch 13: val_accuracy did not improve from 0.88780\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.0729 - accuracy: 0.9775 - val_loss: 0.6977 - val_accuracy: 0.8324\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9785\n",
      "Epoch 14: val_accuracy did not improve from 0.88780\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.0683 - accuracy: 0.9785 - val_loss: 0.4992 - val_accuracy: 0.8753\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9807\n",
      "Epoch 15: val_accuracy improved from 0.88780 to 0.89230, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.0608 - accuracy: 0.9807 - val_loss: 0.4069 - val_accuracy: 0.8923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:43:16.292315: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 0.9524 - accuracy: 0.7017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:45:00.919573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70190, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 116s 138ms/step - loss: 0.9524 - accuracy: 0.7017 - val_loss: 0.9337 - val_accuracy: 0.7019\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.8235\n",
      "Epoch 2: val_accuracy improved from 0.70190 to 0.75640, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 96s 123ms/step - loss: 0.5637 - accuracy: 0.8235 - val_loss: 0.7872 - val_accuracy: 0.7564\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.4145 - accuracy: 0.8683\n",
      "Epoch 3: val_accuracy improved from 0.75640 to 0.82070, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.4145 - accuracy: 0.8683 - val_loss: 0.5289 - val_accuracy: 0.8207\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3133 - accuracy: 0.9003\n",
      "Epoch 4: val_accuracy did not improve from 0.82070\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.3133 - accuracy: 0.9003 - val_loss: 0.5928 - val_accuracy: 0.8150\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.9205\n",
      "Epoch 5: val_accuracy improved from 0.82070 to 0.85690, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 0.2521 - accuracy: 0.9205 - val_loss: 0.4329 - val_accuracy: 0.8569\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.2088 - accuracy: 0.9341\n",
      "Epoch 6: val_accuracy did not improve from 0.85690\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.2088 - accuracy: 0.9341 - val_loss: 0.5400 - val_accuracy: 0.8381\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1687 - accuracy: 0.9462\n",
      "Epoch 7: val_accuracy improved from 0.85690 to 0.87560, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.1687 - accuracy: 0.9462 - val_loss: 0.4213 - val_accuracy: 0.8756\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1417 - accuracy: 0.9543\n",
      "Epoch 8: val_accuracy improved from 0.87560 to 0.87620, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.1417 - accuracy: 0.9543 - val_loss: 0.4291 - val_accuracy: 0.8762\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9617\n",
      "Epoch 9: val_accuracy improved from 0.87620 to 0.88860, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 0.1212 - accuracy: 0.9617 - val_loss: 0.3710 - val_accuracy: 0.8886\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9681\n",
      "Epoch 10: val_accuracy did not improve from 0.88860\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.1008 - accuracy: 0.9681 - val_loss: 0.4302 - val_accuracy: 0.8762\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9706\n",
      "Epoch 11: val_accuracy improved from 0.88860 to 0.89410, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 96s 123ms/step - loss: 0.0921 - accuracy: 0.9706 - val_loss: 0.3783 - val_accuracy: 0.8941\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9742\n",
      "Epoch 12: val_accuracy did not improve from 0.89410\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.0786 - accuracy: 0.9742 - val_loss: 0.4039 - val_accuracy: 0.8859\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9759\n",
      "Epoch 13: val_accuracy did not improve from 0.89410\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 0.0755 - accuracy: 0.9759 - val_loss: 0.4542 - val_accuracy: 0.8865\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9795\n",
      "Epoch 14: val_accuracy improved from 0.89410 to 0.89430, saving model to /Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_0.01_beta1_0.85_beta2_0.99_epochs_15_batch_64.h5\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 0.0643 - accuracy: 0.9795 - val_loss: 0.4062 - val_accuracy: 0.8943\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9811\n",
      "Epoch 15: val_accuracy did not improve from 0.89430\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.0609 - accuracy: 0.9811 - val_loss: 0.4034 - val_accuracy: 0.8921\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAHUCAYAAAAwUBnrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACvPklEQVR4nOzdd3gU5doG8Huz2fQCSUijBQEpUhVBEAgIhC6CHg+CSDuIIipFPWID/AQUlQMWQFEp0lQEBUUkKE0BQRCRIlgAKQktIQnp2bzfH8NsNiSbbJndmdncv+viYrOZnXl2kuzOs8/7Pq9BCCFAREREREREdvNROwAiIiIiIiK9YSJFRERERETkICZSREREREREDmIiRURERERE5CAmUkRERERERA5iIkVEREREROQgJlJEREREREQOYiJFRERERETkICZSREREREREDmIipUFLliyBwWCw/AsICEBsbCy6du2KWbNm4eLFi2UeM23aNBgMBoeOk5OTg2nTpmHbtm0KRa6uU6dOwWAw4I033lBsn+fPn8e0adNw8OBBxfZJ2nb06FFMmzYNp06dKvO9ESNGICEhweMx2WvEiBHo0qWL2mGQFxo4cCACAwNx9epVm9sMHToUJpMJFy5csHu/BoMB06ZNcz1AN/rll1+QmJiI8PBwGAwGzJ07t9ztKnpPld+jL1++7NZYPXWcG82fPx9Llizx6DFlCQkJGDFihNv2787npofff2dt27YNBoPBa64xbWEipWGLFy/G7t27kZycjHfffRetWrXCa6+9hiZNmmDLli2ltv3Pf/6D3bt3O7T/nJwcTJ8+3et/yV1x/vx5TJ8+nYlUFXL06FFMnz693ETqxRdfxLp16zwfFJHKRo8ejby8PKxcubLc72dkZGDdunXo168fYmJiPByde40aNQopKSlYvXo1du/ejcGDB5e7XVV+T1UzkXI3b35u5DpftQMg25o1a4Y2bdpYvr733nsxceJEdOzYEYMGDcIff/xhecOqVasWatWqpVaoRFVC/fr11Q6BSBW9e/dGfHw8PvroI4wbN67M91etWoXc3FyMHj1ahejc6/DhwxgzZgx69+6tdihEpDGsSOlMnTp18OabbyIrKwvvvfee5f7yhvZ9//336NKlCyIjIxEYGIg6derg3nvvRU5ODk6dOoUaNWoAAKZPn24ZRiiXx//880+MHDkSDRs2RFBQEGrWrIn+/fvjt99+K3UMuXS7atUqPP/884iPj0dYWBi6d++O48ePl4l/06ZN6NatG8LDwxEUFIQmTZpg1qxZpbb5+eefcffddyMiIgIBAQFo3bo1Pv30U7vPUXFxMWbMmIE6deogICAAbdq0wXfffVdmuz/++ANDhgxBdHQ0/P390aRJE7z77rulntvtt98OABg5cqTlHE2bNg1ff/01DAYD9u3bZ9n+888/h8FgQN++fUsdp0WLFrj33nstXwshMH/+fLRq1QqBgYGoXr067rvvPvz9999lYtyyZQu6deuGsLAwBAUF4c477yzzXOSf/ZEjR/DAAw8gPDwcMTExGDVqFDIyMuw6Z/b8XNavX4/27dsjKCgIoaGh6NGjR5kqqCOxfPbZZ2jXrp3lmDfddBNGjRpVapvMzEw89dRTqFevHvz8/FCzZk1MmDAB2dnZpbYrLi7G22+/bTmn1apVwx133IH169dbtrE1hMJ6WMiSJUvwr3/9CwDQtWtXy89c/jTyxqF9rVu3RqdOncrs02w2o2bNmhg0aJDlvoKCArzyyito3Lgx/P39UaNGDYwcORKXLl0q83hrly9fRu3atdGhQwcUFhZa7j969CiCg4MxbNiwCh+/YMECtGzZEiEhIQgNDUXjxo3x3HPPVfgYohsZjUYMHz4c+/fvL/M+AEgjKOLi4tC7d29cunQJ48aNQ9OmTRESEoLo6Gjcdddd2LlzZ6XHsTVMXR7yfmOl+JNPPkH79u0RHByMkJAQ9OzZE7/88otdz+nw4cMYMGAAqlevjoCAALRq1QpLly4tc8yioiIsWLDA8npQnsreU2UXLlyo9LXRkfcIW86cOYNBgwYhLCwM4eHhePDBB8t9rbHn/P39998YPHgw4uPj4e/vj5iYGHTr1s0yUiMhIQFHjhzB9u3bLc+7siHQSr7+l0ep947Knpu9x8nMzMSYMWMQGRmJkJAQ9OrVCydOnKj0ecgxvvLKK2jUqJElxhYtWmDevHmWbRy9Zlu5ciX++9//Ii4uDiEhIejfvz8uXLiArKwsPPzww4iKikJUVBRGjhyJa9euldqHwWDA+PHj8d577+Hmm2+Gv78/mjZtitWrV9v1fFy9xtMcQZqzePFiAUDs27ev3O9fu3ZNGI1G0a1bN8t9U6dOFdY/zpMnT4qAgADRo0cP8cUXX4ht27aJFStWiGHDhon09HSRl5cnNm3aJACI0aNHi927d4vdu3eLP//8UwghxPbt28XkyZPFmjVrxPbt28W6devEPffcIwIDA8Xvv/9uOc7WrVsFAJGQkCCGDh0qvv76a7Fq1SpRp04d0bBhQ1FUVGTZ9oMPPhAGg0F06dJFrFy5UmzZskXMnz9fjBs3zrLN999/L/z8/ESnTp3EJ598IjZt2iRGjBghAIjFixdXeN5OnjwpAIjatWuLjh07is8//1x89tln4vbbbxcmk0ns2rXLsu2RI0dEeHi4aN68uVi2bJnYvHmzmDx5svDx8RHTpk0TQgiRkZFh+Vm88MILlnN05swZkZWVJUwmk5g5c6Zln4888ogIDAwUwcHBoqCgQAghxIULF4TBYBDz58+3bDdmzBhhMpnE5MmTxaZNm8TKlStF48aNRUxMjEhNTbVs9/HHHwuDwSDuuecesXbtWrFhwwbRr18/YTQaxZYtW8r87Bs1aiReeuklkZycLObMmSP8/f3FyJEjKzxn9v5cVqxYIQCIpKQk8cUXX4hPPvlE3HbbbcLPz0/s3LnT4Vh27dolDAaDGDx4sNi4caP4/vvvxeLFi8WwYcMs22RnZ4tWrVqJqKgoMWfOHLFlyxYxb948ER4eLu666y5RXFxs2XbYsGHCYDCI//znP+LLL78U33zzjZgxY4aYN2+eZRsAYurUqWWef926dcXw4cOFEEJcvHhRzJw5UwAQ7777ruVnfvHiRSGEEMOHDxd169a1PHbevHkCgDhx4kSpfW7cuFEAEOvXrxdCCGE2m0WvXr1EcHCwmD59ukhOThYffPCBqFmzpmjatKnIycmp8Gf0ww8/CF9fXzFx4kTLuWnatKlo3LixuHbtms3HrVq1SgAQjz/+uNi8ebPYsmWLWLhwoXjiiScqPB5Ref744w9hMBjEhAkTSt1/5MgRAUA8++yzQgghfv/9d/Hoo4+K1atXi23btomvvvpKjB49Wvj4+IitW7eWeuyNf5c3vpfJ5NfikydPWu6bMWOGMBgMYtSoUeKrr74Sa9euFe3btxfBwcHiyJEjFT6X33//XYSGhor69euLZcuWia+//lo88MADAoB47bXXhBDS68Hu3bsFAHHfffdZXg/KU9l7qiOv0/a+R5RHPk7dunXF008/Lb799lsxZ84cERwcLFq3bm15b3Lk/DVq1Eg0aNBAfPzxx2L79u3i888/F5MnT7b8LA8cOCBuuukm0bp1a8vzPnDggM0YlX79t34Nd/Sxlb13VPTc7D1OcXGx6Nq1q/D39xczZswQmzdvFlOnThU33XSTzfcla7NmzRJGo1FMnTpVfPfdd2LTpk1i7ty5lmsVIRy/Zqtbt64YMWKE2LRpk1i4cKEICQkRXbt2FT169BBPPfWU2Lx5s3jttdeE0WgUjz/+eKl45Ouspk2bilWrVon169eLXr16CQDis88+K3Ms6795V67xtIqJlAZVlkgJIURMTIxo0qSJ5esb33zWrFkjAIiDBw/a3MelS5fs+iMWQoiioiJRUFAgGjZsaLmYE6LkD6VPnz6ltv/0008FAMubTlZWlggLCxMdO3Ys9SJ2o8aNG4vWrVuLwsLCUvf369dPxMXFCbPZbPOxciIVHx8vcnNzLfdnZmaKiIgI0b17d8t9PXv2FLVq1RIZGRml9jF+/HgREBAg0tLShBBC7Nu3z+YfeMeOHcVdd91l+bpBgwbi6aefFj4+PmL79u1CiJIERL7Qlt+U33zzzVL7OnPmjAgMDBTPPPOMEEJ6gY6IiBD9+/cvtZ3ZbBYtW7YUbdu2tdwn/+xnz55dattx48aJgICACs+3PT8Xs9ks4uPjRfPmzUud/6ysLBEdHS06dOjgcCxvvPGGACCuXr1qM7ZZs2YJHx+fMn8H8u/2xo0bhRBC7NixQwAQzz//vM19CWFfIiWEEJ999lmZF3/ZjYnU5cuXhZ+fn3juuedKbXf//feLmJgYy++xnNB8/vnnpbaTf7+sE21bXnvtNQFArFu3TgwfPlwEBgaKQ4cOVfiY8ePHi2rVqlW6byJ7JSYmiqioqFIX5JMnTy73AwVZUVGRKCwsFN26dRMDBw4s9T1nE6l//vlH+Pr6lrnIy8rKErGxseL++++v8HkMHjxY+Pv7i3/++afU/b179xZBQUGlXpsAiMcee6zC/QlR8Xuqva+N9r5H2CIfx/p9WoiS96Lly5cLIew/f5cvXxYAxNy5cys87i233CISExMr3Eam5Ou/EGVfw5V+77D13Ow9zjfffCMAlPpgTwgpkbXnGqxfv36iVatWFW5zo8qu2W68tpgwYYIAUOZDtnvuuUdERESUug+ACAwMLJXUFxUVicaNG4sGDRqUOZb1e6kr13haxaF9OiWEqPD7rVq1gp+fHx5++GEsXbrUoSEBAFBUVISZM2eiadOm8PPzg6+vL/z8/PDHH3/g2LFjZba/++67S33dokULAMDp06cBALt27UJmZibGjRtnc2jEn3/+id9//x1Dhw61xCD/69OnD1JSUsodLnijQYMGISAgwPJ1aGgo+vfvjx07dsBsNiMvLw/fffcdBg4ciKCgoDLHycvLw549eyo9Trdu3fDjjz8iNzcXp0+fxp9//onBgwejVatWSE5OBiANzatTpw4aNmwIAPjqq69gMBjw4IMPljpubGwsWrZsaZmkvGvXLqSlpWH48OGltisuLkavXr2wb9++MkMHyvsZ5OXlldvlUWbPz+X48eM4f/48hg0bBh+fkpeMkJAQ3HvvvdizZw9ycnIcikUeMnn//ffj008/xblz58oc96uvvkKzZs3QqlWrUuegZ8+epToBffPNNwCAxx57zObzdJfIyEj0798fS5cuRXFxMQAgPT0dX375JR566CH4+vpanku1atXQv3//Us+lVatWiI2NtWty+tNPP42+ffvigQcewNKlS/H222+jefPmFT6mbdu2uHr1Kh544AF8+eWXHu/kRd5n9OjRuHz5smXoU1FREZYvX45OnTpZXucAYOHChbj11lsREBAAX19fmEwmfPfdd+W+fzjj22+/RVFRER566KFSf1MBAQFITEys9G/q+++/R7du3VC7du1S948YMQI5OTkON2+yV2Wvjfa+R1RGfh+V3X///fD19cXWrVsB2H/+IiIiUL9+fbz++uuYM2cOfvnlF8trnbOUfP0vj6feO+w9jnzOb/yZDBkyxK7jtG3bFr/++ivGjRuHb7/9FpmZmWW2cfSarV+/fqW+btKkCQCUmZrQpEkTpKWllRne161bt1JNZYxGI/7973/jzz//xNmzZ8t9Hkpd42kNEykdys7OxpUrVxAfH29zm/r162PLli2Ijo7GY489hvr166N+/fqlxtRWZNKkSXjxxRdxzz33YMOGDfjpp5+wb98+tGzZErm5uWW2j4yMLPW1v78/AFi2lcdmV9QQQ26Z+9RTT8FkMpX6J09utudCMDY2ttz7CgoKcO3aNVy5cgVFRUV4++23yxynT58+dh+ne/fuyM/Pxw8//IDk5GRERUWhdevW6N69u6Wr4nfffYfu3buXeo5CCMTExJQ59p49eyzHlc/FfffdV2a71157DUIIpKWllYqnsp9Beez5uVy5cgUAEBcXV+Z78fHxKC4uRnp6ukOxdO7cGV988YXljbxWrVpo1qwZVq1aZXnMhQsXcOjQoTLPPzQ0FEIIy7m6dOkSjEZjuT93Txg1ahTOnTtnSZ5XrVqF/Pz8UnMjLly4gKtXr8LPz6/M80lNTbXr902eb5GXl4fY2NhK50YBwLBhw/DRRx/h9OnTuPfeexEdHY127dpZYiVy1H333Yfw8HAsXrwYALBx40ZcuHChVJOJOXPm4NFHH0W7du3w+eefY8+ePdi3bx969epV4euRI+TXyNtvv73M39Qnn3xS6d/UlStXbL6myd93h8peG+19j6jMja+Hvr6+iIyMtDwve8+fwWDAd999h549e2L27Nm49dZbUaNGDTzxxBPIyspy6hwo+fpfHk+9d9h7nCtXrljOvzV7jztlyhS88cYb2LNnD3r37o3IyEh069YNP//8s2UbR6/ZIiIiSn3t5+dX4f15eXmVxi7fZ+tvR6lrPK1h1z4d+vrrr2E2mytdL6ZTp07o1KkTzGYzfv75Z7z99tuYMGECYmJibLZvlS1fvhwPPfQQZs6cWer+y5cvo1q1ag7HLE/CtfVJBQBERUUBkF40rCfpW2vUqFGlx0pNTS33Pj8/P4SEhMBkMsFoNGLYsGE2P4mqV69epcdp164dQkJCsGXLFpw6dQrdunWDwWBAt27d8Oabb2Lfvn34559/SiVSUVFRMBgM2Llzp+UN1Jp8n3wu3n77bdxxxx3lHl+JFsP2/FzkF/+UlJQy3zt//jx8fHxQvXp1h489YMAADBgwAPn5+dizZw9mzZqFIUOGICEhAe3bt0dUVBQCAwPx0Ucflft4+RzVqFEDZrMZqamp5V4Yyfz9/ZGfn1/mflcvmHr27In4+HgsXrwYPXv2xOLFi9GuXTs0bdq0VKyRkZHYtGlTufsIDQ2t9DgpKSl47LHH0KpVKxw5cgRPPfUU3nrrrUofN3LkSIwcORLZ2dnYsWMHpk6din79+uHEiROoW7eu/U+UCEBgYCAeeOABLFq0CCkpKfjoo48QGhpqadICSO8fXbp0wYIFC0o91p4Lb3k0QX5+fqnXyBsvsOS//zVr1jj1exwZGWnzNc16/55m73tEZVJTU1GzZk3L10VFRbhy5Yrl9dyR81e3bl18+OGHAIATJ07g008/xbRp01BQUICFCxfaFc+NlHr9t/U9Jd87XD1OZGRkmfMPlH+tUh5fX19MmjQJkyZNwtWrV7FlyxY899xz6NmzJ86cOYOgoCDFr9kqY+s6Cyj7YYFMqWs8rWEipTP//PMPnnrqKYSHh2Ps2LF2PcZoNKJdu3Zo3LgxVqxYgQMHDmDw4MEVViwMBkOZF+yvv/4a586dQ4MGDRyOu0OHDggPD8fChQsxePDgcoeRNWrUCA0bNsSvv/5a5sXAEWvXrsXrr79ueUPOysrChg0b0KlTJxiNRgQFBaFr16745Zdf0KJFC8snLuWp6ByZTCZ07twZycnJOHPmDF599VUAUgLr6+uLF154wZJYyfr164dXX30V586dw/3332/zuHfeeSeqVauGo0ePYvz48U6dB3vY+3OpWbMmVq5ciaeeesqyTXZ2Nj7//HNLJz9n+fv7IzExEdWqVcO3336LX375Be3bt0e/fv0wc+ZMREZGVpjY9u7dG7NmzcKCBQvw8ssv29wuISEBhw4dKnXf999/X2bIgj2VPGtyUj537lzs3LkTP//8c6mOmoD0c1+9ejXMZjPatWtn136tmc1mPPDAAzAYDPjmm2+wYsUKPPXUU+jSpYvNN6QbBQcHo3fv3igoKMA999yDI0eOMJEip4wePRoLFy7E66+/jo0bN2LEiBGlXgPKe/84dOgQdu/eXWYo3Y3kjmiHDh2yDAEDgA0bNpTarmfPnvD19cVff/1Vqiuqvbp164Z169bh/PnzpUZ3LFu2DEFBQTY/wKqIo68d5bH3PaIyK1aswG233Wb5+tNPP0VRUZHlA1hnz9/NN9+MF154AZ9//jkOHDhgud/f39+p5+3q6395lH7vsPXc7D1O165dMXv2bKxYsQJPPPGE5X5ba7JVpFq1arjvvvtw7tw5TJgwAadOnULTpk0Vv2arzHfffYcLFy5YPtA1m8345JNPUL9+fZsjXJS6xtMaJlIadvjwYcv40YsXL2Lnzp1YvHgxjEYj1q1bZ6kmlGfhwoX4/vvv0bdvX9SpUwd5eXmWT03kCkloaCjq1q2LL7/8Et26dUNERASioqKQkJCAfv36YcmSJWjcuDFatGiB/fv34/XXX3d6raqQkBC8+eab+M9//oPu3btjzJgxiImJwZ9//olff/0V77zzDgDgvffeQ+/evdGzZ0+MGDECNWvWRFpaGo4dO4YDBw7gs88+q/RYRqMRPXr0wKRJk1BcXIzXXnsNmZmZmD59umWbefPmoWPHjujUqRMeffRRJCQkICsrC3/++Sc2bNiA77//HoA0RDIwMBArVqxAkyZNEBISgvj4eMsbb7du3TB58uRS5zUwMBAdOnTA5s2b0aJFC0RHR1uOe+edd+Lhhx/GyJEj8fPPP6Nz584IDg5GSkoKfvjhBzRv3hyPPvooQkJC8Pbbb2P48OFIS0vDfffdh+joaFy6dAm//vorLl26VObTXnf9XHx8fDB79mwMHToU/fr1w9ixY5Gfn4/XX38dV69etSSQjnjppZdw9uxZdOvWDbVq1cLVq1cxb948mEwmJCYmAgAmTJiAzz//HJ07d8bEiRPRokULFBcX459//sHmzZsxefJktGvXDp06dcKwYcPwyiuv4MKFC+jXrx/8/f3xyy+/ICgoCI8//jgAaZjbiy++iJdeegmJiYk4evQo3nnnHYSHh5eKrVmzZgCA999/H6GhoQgICEC9evVsfsoGSMP7XnvtNQwZMgSBgYH497//Xer7gwcPxooVK9CnTx88+eSTaNu2LUwmE86ePYutW7diwIABGDhwoM39T506FTt37sTmzZsRGxuLyZMnY/v27Rg9ejRat25t8018zJgxCAwMxJ133om4uDikpqZi1qxZCA8PL3WRSuSINm3aoEWLFpg7dy6EEGXWjurXrx/+7//+D1OnTkViYiKOHz+Ol19+GfXq1UNRUVGF++7Tpw8iIiIwevRovPzyy/D19cWSJUtw5syZUtslJCTg5ZdfxvPPP4+///4bvXr1QvXq1XHhwgXs3bsXwcHBpV7zbzR16lR89dVX6Nq1K1566SVERERgxYoV+PrrrzF79uwyrwv2qOg91V72vkdUZu3atfD19UWPHj1w5MgRvPjii2jZsqUlObP3/B06dAjjx4/Hv/71LzRs2BB+fn74/vvvcejQITz77LOW4zVv3hyrV6/GJ598gptuugkBAQE253Aq+fpfHqXfO2w9N3uPk5SUhM6dO+OZZ55BdnY22rRpgx9//BEff/yxXb8T/fv3t6wrWqNGDZw+fRpz585F3bp1LfMSlb5mq0xUVBTuuusuvPjiiwgODsb8+fPx+++/V9oCXYlrPM1Rrc0F2SR3J5L/+fn5iejoaJGYmChmzpxpacVs7cZOR7t37xYDBw4UdevWFf7+/iIyMlIkJiZa2jHLtmzZIlq3bi38/f0FAEvnm/T0dDF69GgRHR0tgoKCRMeOHcXOnTtFYmJiqe41clcW65aXQpR00Lux293GjRtFYmKiCA4OFkFBQaJp06aWVrOyX3/9Vdx///0iOjpamEwmERsbK+666y6xcOHCCs+bfMzXXntNTJ8+XdSqVUv4+fmJ1q1bi2+//bbc7UeNGiVq1qwpTCaTqFGjhujQoYN45ZVXSm23atUq0bhxY2Eymcp02Pn1118FANGwYcNSj5G78UyaNKncWD/66CPRrl07ERwcLAIDA0X9+vXFQw89JH7++edS223fvl307dtXRERECJPJJGrWrCn69u1b6nzLP/tLly6Vemx57YJtsefn8sUXX4h27dqJgIAAERwcLLp16yZ+/PHHUtvYG8tXX30levfuLWrWrGn5/e7Tp0+pVupCSK3+X3jhBdGoUSPh5+dnaVk/ceLEUh2DzGaz+N///ieaNWtm2a59+/Ziw4YNlm3y8/PFM888I2rXri0CAwNFYmKiOHjwYJmOT0IIMXfuXFGvXj1hNBpL/R7f2LXPWocOHQQAMXTo0HK/X1hYKN544w3RsmVLERAQIEJCQkTjxo3F2LFjxR9//FHuY4QQYvPmzcLHx6dMZ6crV66IOnXqiNtvv13k5+eX+9ilS5eKrl27ipiYGOHn5yfi4+PF/fffX2m3P6LKyK3/mzZtWuZ7+fn54qmnnhI1a9YUAQEB4tZbbxVffPFFuX8/N76mCiHE3r17RYcOHURwcLCoWbOmmDp1qvjggw/KfT374osvRNeuXUVYWJjw9/cXdevWFffdd1+pJSJs+e2330T//v1FeHi48PPzEy1btiy3Qyvs7NonhO33VEdfp+19j7iRfJz9+/eL/v37i5CQEBEaGioeeOABceHChTLbV3b+Lly4IEaMGCEaN24sgoODRUhIiGjRooX43//+V2p5k1OnTomkpCQRGhpqaa9ti9Kv/+W9hiv53lHRc7P3OFevXhWjRo0S1apVE0FBQaJHjx7i999/t6tr35tvvik6dOggoqKihJ+fn6hTp44YPXq0OHXqlGUbV6/ZbHWLLu/3Vv57mD9/vqhfv74wmUyicePGYsWKFaUeW17XPiGcv8bTKoMQlbR/IyIiIiKiKs9gMOCxxx6zjCSq6ti1j4iIiIiIyEFMpIiIiIiIiBzEZhNERERERFQpzggqjRUpIiIiIiIiBzGRIiIiIiIichATKSIiIiIiIgdxjhSA4uJinD9/HqGhoTAYDGqHQ0RUZQghkJWVhfj4ePj48LM9a3xvIiJSh73vTUykAJw/fx61a9dWOwwioirrzJkzqFWrltphaArfm4iI1FXZe5OqidSOHTvw+uuvY//+/UhJScG6detwzz33WL4vhMD06dPx/vvvIz09He3atcO7776LW265xbJNfn4+nnrqKaxatQq5ubno1q0b5s+f79AbcmhoKADpZIWFhTn8PAoLC7F582YkJSXBZDI5/Hg1MXZ1MHZ1MHb12Io/MzMTtWvXtrwOU4mq9t6kt3gB/cWst3gB/cWst3gB/cXsiXjtfW9SNZHKzs5Gy5YtMXLkSNx7771lvj979mzMmTMHS5Yswc0334xXXnkFPXr0wPHjxy1PbMKECdiwYQNWr16NyMhITJ48Gf369cP+/fthNBrtikMeMhEWFub0m1VQUBDCwsJ08QtojbGrg7Grg7Grp7L4OXStrKr23qS3eAH9xay3eAH9xay3eAH9xezJeCt7b1I1kerduzd69+5d7veEEJg7dy6ef/55DBo0CACwdOlSxMTEYOXKlRg7diwyMjLw4Ycf4uOPP0b37t0BAMuXL0ft2rWxZcsW9OzZ02PPhYiIiIiIqg7NzpE6efIkUlNTkZSUZLnP398fiYmJ2LVrF8aOHYv9+/ejsLCw1Dbx8fFo1qwZdu3aZTORys/PR35+vuXrzMxMAFKGW1hY6HCs8mOceazaGLs6GLs6GLt6bMWv1+dDRESk2UQqNTUVABATE1Pq/piYGJw+fdqyjZ+fH6pXr15mG/nx5Zk1axamT59e5v7NmzcjKCjI6ZiTk5OdfqzaGLs6GLs6GLt6bow/JydHpUiIiIhco9lESnbj2EQhRKXjFSvbZsqUKZg0aZLla3lCWVJSktPj0JOTk9GjRw9djC21xtjVwdjVwdjVYyt+eUQAERGR3mg2kYqNjQUgVZ3i4uIs91+8eNFSpYqNjUVBQQHS09NLVaUuXryIDh062Ny3v78//P39y9xvMplcukBx9fFqYuzqYOzqYOzquTF+PT8XIiKq2jS7+mG9evUQGxtbahhIQUEBtm/fbkmSbrvtNphMplLbpKSk4PDhwxUmUkRERERERK5QtSJ17do1/Pnnn5avT548iYMHDyIiIgJ16tTBhAkTMHPmTDRs2BANGzbEzJkzERQUhCFDhgAAwsPDMXr0aEyePBmRkZGIiIjAU089hebNm1u6+BERERERESlN1UTq559/RteuXS1fy/OWhg8fjiVLluCZZ55Bbm4uxo0bZ1mQd/PmzaUWx/rf//4HX19f3H///ZYFeZcsWWL3GlJERERERESOUjWR6tKlC4QQNr9vMBgwbdo0TJs2zeY2AQEBePvtt/H222+7IUIiIiIiIqKyNDtHSjfMZhi2b0fNHTtg2L4dMJvVjkhZZjOwbRuwapX0v7c9PyIiL2QuFvjpZBr2Xzbgp5NpMBfb/tCSiIico9mufbqwdi3w5JPwPXsWbQBgzhygVi1g3jxg0CC1o3Pd9eeHs2dL7vOm50dE5IU2HU7B9A1HkZKRB8CIZX/8jLjwAEzt3xS9msVV+ngiIrIPK1LOWrsWuO++0kkGAJw7J92/dq06cSnFHc+P1S0iIrfadDgFjy4/cD2JKpGakYdHlx/ApsMpKkVGROR9mEg5w2yWKjXlze+S75swQb+Jgjue39q1QEIC0LUrMGSI9H9Cgv4TTiIijTAXC0zfcBTlDeKT75u+4SiH+RERKYSJlDN27ixbqbEmBHDmjLSdHtn7/GbMAPbsAf75BygosL29t1fviIg0YO/JtDKVKGsCQEpGHvaeTPNcUEREXoxzpJyRYufQCHu30xp74546Vfoni4oC4uKA+HjpX1wcEBsLTJ9uu7plMEjVrQEDALasJyJy2sUs20mUM9sREVHFmEg5I87Oybr2bqc19sbdtCmQnS0lXgUFwOXL0r/ffrP/WNbVuy5dnAqXiIiA6NAARbcjIqKKMZFyRqdOUve6c+fKr7QYDNL3O3XyfGxKsPf5HTokVZGEANLSgPPnpaTK+v+ffgL27av8mHqt3hERaUTbehGICw9AakZeufOkDABiwwPQtl6Ep0MjIvJKTKScYTRKLcDvu09KKqyTDYNB+n/uXP0OVXP0+RkMQGSk9K9589L72rZNaixRGb1W74iINMLoY8DU/k3x6PIDZb53/ZUbU/s3hdHHUOb7RETkODabcNagQcCaNUDNmqXvr1VLul/v6ywp9fzk6pbBxhu3wQDUrq3f6h0RkYb0ahaHBQ/eihoh/qXujw0PwIIHb+U6UkRECmIi5YpBg4BTpyDq1AEAmF9/HTh5Uv9JlOz680N4uPT1Rx85/vzk6hZQNpnyhuodEZHG9GoWh28ndLZ8/dHwW/HDf+9iEkVEpDAmUq4yGiHi4wEAIiHB+xICoxHIzZVud+/u3PPz9uodEZHGhAeZLLebxIZyOB8RkRswkVJCWJj0f2amunG4Q35+yRpR8vN0hlzdevFF6esWLbyrekdEpCFGHwNC/KVp0Jm5RSpHQ0TknZhIKeF6gmHwxkQqI6Pkdmioa/syGktanBcVeV/1johIQ8IDrydSeYUqR0JE5J2YSClBrtRYJx3eQk4OQ0MBHwV+XWrUkP6/dMn1fRERkU2hAdLwvsw8VqSIiNyBiZQChNyMwZsrUvJzdJWcSF25AhQXK7NPIiIqw1KRymVFiojIHZhIKUEe8ubNiZQr86OsRUZK/xcXS4v4EhGRW4SxIkVE5FZMpJRwvVrjlXOk5OekVEXKZAKqVZNuc3gfEZHbhAawIkVE5E5MpBQgvLlrn9JD+wDOkyIi8oDwQFakiIjciYmUErw5kZKfk1JD+wAmUkREHmCpSLFrHxGRWzCRUoI8tM8bu/axIkVEpEthAVxHiojInZhIKUGu1mRlqRuHO7AiRUSkSxzaR0TkXkykFCC8eR0pVqSIiHSJQ/uIiNyLiZQSrOdICaFuLEpjRYqIvFh6ejqGDRuG8PBwhIeHY9iwYbh69WqFj7l27RrGjx+PWrVqITAwEE2aNMGCBQss309LS8Pjjz+ORo0aISgoCHXq1METTzyBDA9/2GapSHFoHxGRW/iqHYBXkOdICQFcu1ayrpQ3cGdF6vJl5fZJROSEIUOG4OzZs9i0aRMA4OGHH8awYcOwYcMGm4+ZOHEitm7diuXLlyMhIQGbN2/GuHHjEB8fjwEDBuD8+fM4f/483njjDTRt2hSnT5/GI488gvPnz2PNmjWeemolc6RYkSIicgsmUkoICECx0Qgfs1mq4HhTIsWKFBF5qWPHjmHTpk3Ys2cP2rVrBwBYtGgR2rdvj+PHj6NRo0blPm737t0YPnw4unTpAkBKvt577z38/PPPGDBgAJo1a4bPP//csn39+vUxY8YMPPjggygqKoKvb/lvvfn5+cjPz7d8nXn99bewsBCFhY4nQ4HXD5OZW4SCggIYDAaH9+FJ8nN05rmqRW8x6y1eQH8x6y1eQH8xeyJee/fNREoJBgMKg4Lgn5UlVXBq1lQ7IuVwjhQReandu3cjPDzckkQBwB133IHw8HDs2rXLZiLVsWNHrF+/HqNGjUJ8fDy2bduGEydOYN68eTaPlZGRgbCwMJtJFADMmjUL06dPL3P/5s2bERQU5MAzk+SbAcAXZiHwxVffwN/o8C5UkZycrHYIDtNbzHqLF9BfzHqLF9BfzO6MNycnx67tmEgppEhOpLxtLSl3V6SEADT+KSkReafU1FRER0eXuT86Ohqpqak2H/fWW29hzJgxqFWrFnx9feHj44MPPvgAHTt2LHf7K1eu4P/+7/8wduzYCuOZMmUKJk2aZPk6MzMTtWvXRlJSEsKceA0uKCjAs/u2olgYcEfnuxAXHuDwPjypsLAQycnJ6NGjB0wmk9rh2EVvMestXkB/MestXkB/MXsi3kw7r+eZSCmkUP600Ns697mjIhUVJf1fWCglakrum4iqvGnTppVb2bG2b98+ACh3uJsQosJhcG+99Rb27NmD9evXo27dutixYwfGjRuHuLg4dO/evdS2mZmZ6Nu3L5o2bYqpU6dWGJO/vz/8/f3L3G8ymZy+WAg0AtlFQE6R0MUFEuDa81WL3mLWW7yA/mLWW7yA/mJ2Z7z27peJlEKKvDGREsI9FanAQCA4GMjOlqpSTKSISEHjx4/H4MGDK9wmISEBhw4dwoULF8p879KlS4iJiSn3cbm5uXjuueewbt069O3bFwDQokULHDx4EG+88UapRCorKwu9evVCSEgI1q1bp8oFSpCvlEixcx8RkfKYSCnEUpHypqF9166VtHNXOtmpUaMkkWrQQNl9E1GVFhUVhSi58l2B9u3bIyMjA3v37kXbtm0BAD/99BMyMjLQoUOHch8jN37w8Sm9eojRaERxcbHl68zMTPTs2RP+/v5Yv349AgLUGVYXeH1eVEauPiaRExHpCdeRUohXVqTk5+LrCyh9EcCGE0SksiZNmqBXr14YM2YM9uzZgz179mDMmDHo169fqUYTjRs3xrp16wAAYWFhSExMxNNPP41t27bh5MmTWLJkCZYtW4aBAwcCkCpRSUlJyM7OxocffojMzEykpqYiNTUVZrPZo88xyFf6MCyTiRQRkeJYkVJIkTdWpOTnEh6ufEMIJlJEpAErVqzAE088gaSkJADA3XffjXfeeafUNsePHy+1mO7q1asxZcoUDB06FGlpaahbty5mzJiBRx55BACwf/9+/PTTTwCABjdU3E+ePImEhAQ3PqPSLC3QuZYUEZHimEgpxCubTcjPRcn5UTImUkSkAREREVi+fHmF2wh5iPN1sbGxWLx4sc3tu3TpUuYxauHQPiIi9+HQPoV4fUVKaUykiIjcznpRXiIiUhYTKYUUBgZKN7yxIuXOROryZeX3TUREAIBAeY4Uh/YRESmOiZRCioKDpRveWJHi0D4iIl3i0D4iIvdhIqUQr54jxaF9RES6FGQZ2sdEiohIaUykFOLVc6TcUZGS13hhIkVE5DbyHClWpIiIlMdESiGsSDmIFSkiIrcLMkpzpLLy2GyCiEhpTKQUwoqUg+REKidH+kdERIoL5NA+IiK3YSKlEEtFKicHKPSSNyx3VqRCQwE/P+k2q1JERG4hJ1JZ+UUwF2tjbSsiIm/BREohRXL7cwDIylIvECW5syJlMHB4HxGRm8ld+wAgiy3QiYgUxURKIcLXF8Lb5km5syIFMJEiInIzXx8g0CS91XNRXiIiZTGRUpJcufGWRMqdFSmAiRQRkQeEBZgAsHMfEZHSmEgpSU44vKXhBCtSRES6F3Z9olQmh/YRESmKiZSChLdVpOTn4e6K1OXL7tk/ERGxIkVE5CZMpJQkV268oSJVWAjk5kq3WZEiItItS0WKiRQRkaKYSCkpNFT63xsqUtbJoPy8lMZEiojI7eSKFIf2EREpi4mUkrypIiU/h6AgwGRyzzGioqT/mUgREblNWIBUkeLQPiIiZTGRUpBXzZFy9/wogBUpIiIPCAu8XpFi+3MiIkUxkVKSN3Xtk5+Du+ZHAUykiIg8QK5IcWgfEZGymEgpSU46vKki5YlEKiMDKChw33GIiKqwUHbtIyJyCyZSChLeWJFy59C+6tUBo1G6zRboRERuEc6ufUREbsFESkneOEfKnRUpHx8gMlK6zeF9RERuUdK1j3OkiIiUxERKSaxIOY7zpIiI3EpeR4pD+4iIlMVESkmcI+U4JlJERG5lqUgxkSIiUhQTKQUJeeFaVqTsJydSnCNFROQWcte+/KJi5BWaVY6GiMh7MJFSknVFSgh1Y3EVK1JERF4hxN8XBoN0my3QiYiUw0RKSXL1pqgIyM1VNxZXeaoiFRUl/c9EiojILXx8DAj1lzv3seEEEZFSmEgpKSQEJR/76Xx4HytSREReIyyQa0kRESlN04lUUVERXnjhBdSrVw+BgYG46aab8PLLL6O4uNiyjRAC06ZNQ3x8PAIDA9GlSxccOXJEnYANBu9pgS7Hz659RES6Fx4ot0BnIkVEpBRNJ1KvvfYaFi5ciHfeeQfHjh3D7Nmz8frrr+Ptt9+2bDN79mzMmTMH77zzDvbt24fY2Fj06NEDWVlZ6gQtV3D0XpGS42dFiohI99i5j4hIeZpOpHbv3o0BAwagb9++SEhIwH333YekpCT8/PPPAKRq1Ny5c/H8889j0KBBaNasGZYuXYqcnBysXLlSnaBZkXIMEykiIrezVKSYSBERKcZX7QAq0rFjRyxcuBAnTpzAzTffjF9//RU//PAD5s6dCwA4efIkUlNTkZSUZHmMv78/EhMTsWvXLowdO7bc/ebn5yM/P9/ydeb16kthYSEKCx1/k5EfU1hYCGNYGHwAFKWlQTixL0+zjt1CCPhmZsIAoDAoCHDn86hWDSYA4soVFOXlAUaj3Q8tN3adYOzqYOzqsRW/Xp+P3siL8mbmsdkEEZFSNJ1I/fe//0VGRgYaN24Mo9EIs9mMGTNm4IEHHgAApKamAgBiYmJKPS4mJganT5+2ud9Zs2Zh+vTpZe7fvHkzgoKCnI43OTkZd+TlIQbAbz/8gH/8/Z3el6clJydbbhvz89GvSHqz3bxnD4oCA912XENREe4GYBACWz79FAVODCW0jl1vGLs6GLt6bow/JydHpUiqFnloH5tNEBEpR9OJ1CeffILly5dj5cqVuOWWW3Dw4EFMmDAB8fHxGD58uGU7g9wp7zohRJn7rE2ZMgWTJk2yfJ2ZmYnatWsjKSkJYU4MZSssLERycjJ69OiBgJUrgQMH0CIhAc369HF4X55mHbvJJL3R4nqCKgwGJA0aVNKJ0E1E9eowpKeje8uWQNOmdj+u3Nh1grGrg7Grx1b8mXqfT6oTHNpHRKQ8TSdSTz/9NJ599lkMHjwYANC8eXOcPn0as2bNwvDhwxEbGwtAqkzFxcVZHnfx4sUyVSpr/v7+8C+nWmQymVy6QDGZTPCpXh0AYLx2DUYdXeyUeu7XPyE2hIXB5Ofn/oPXqAGkp8N09SrgxDlz9eemJsauDsaunhvj1/Nz0ZMwdu0jIlKcpptN5OTkwMendIhGo9HS/rxevXqIjY0tNVSkoKAA27dvR4cOHTwaq4Vc0dLzp6ye6tgnkxtOXL7smeMREVUx8hwpDu0jIlKOpitS/fv3x4wZM1CnTh3ccsst+OWXXzBnzhyMGjUKgDSkb8KECZg5cyYaNmyIhg0bYubMmQgKCsKQIUPUCVpOPvTctc9Ti/HK2LmPiMitSob2sdkEEZFSNJ1Ivf3223jxxRcxbtw4XLx4EfHx8Rg7dixeeuklyzbPPPMMcnNzMW7cOKSnp6Ndu3bYvHkzQkND1QnamypS7m59LouKkv5nIkVE5BaWdaQ4tI+ISDGaTqRCQ0Mxd+5cS7vz8hgMBkybNg3Tpk3zWFwVYkXKcaxIERG5lVyR4tA+IiLlaHqOlC6xIuU4JlJERG4VZtW1TwihcjRERN6BiZTSWJFyHBMpIiK3kof2FQvgWj7nSRERKYGJlNLkKo6eEylWpIiIvEqAyQd+RuktPzOPiRQRkRKYSClNruLoeWgfK1JERF7FYDBYWqBzUV4iImUwkVKaXMXJygLMZnVjcZacSHm6InX5MsCx+0REbiEP72PDCSIiZTCRUpp1FefaNfXicIVaC/IWFup7SCQRkYZZN5wgIiLXMZFSmr8/4Ocn3dZrUuDpilRAABASIt3m8D4iIrewJFKcI0VEpAgmUu6g93lSnq5IAaWH9xERkeK4lhQRkbKYSLmD3jv3eboiBQBRUdL/rEgREblFWACbTRARKYmJlDuwIuU4du4jInKrMFakiIgUxUTKHfS8KK/ZLHUcBDxbkWIiRUTkVuGWOVJMpIiIlMBEyh3kBESPFSnrToOsSBEReQ25/XlmLptNEBEpgYmUO+i5IiXH7OcndSD0FCZSRERuxQV5iYiUxUTKHfRckVJjfhTARIqIyM04tI+ISFlMpNzBGypSTKSIiLxKydA+JlJEREpgIuUO3lCR8mSjCYCJFBGRm3EdKSIiZTGRcgdWpBzHRIqIyK3k9ufZBWYUmYtVjoaISP+YSLmDnhfkVbsilZsLZGd79thERFVA6PUFeQEgK4+d+4iIXMVEyh30vCCvWhWpkJCSLoGXL3v22EREVYDJ6INgPyMADu8jIlICEyl30HNFSo7Z0xUpgwGIipJuc3gfEZFbhLFzHxGRYphIuYOeK1JqtT8HOE+KiMjN5M59rEgREbmOiZQ7sCLlHCZSRERuZVlLKpdzpIiIXMVEyh3kak5+vvRPT1iRIiLyWmGBUsMJDu0jInIdEyl3CA0tua234X2sSBERea0wriVFRKQYJlLuYDRKXegA/SVSrEgREXkteY5UJhMpIiKXMZFyF70uysuKFBGR12LXPiIi5TCRchc5EWFFyn5MpIiI3CrcMrSPzSaIiFzFRMpdWJFyHBMpIiK3Cgu43myCQ/uIiFzGRMpd9FiRsu4yyIoUEZHXYbMJIiLlMJFyFz1WpKyTPuvOg54SFVUSR0GB549PROTlwjlHiohIMUyk3EWPFSk51pAQqfOgp1WvXnLcy5c9f3wiIi9X0rWPc6SIiFzFRMpd9FiRkmNVY1gfAPj4AJGR0m0O7yMiUlx4UEn7cyGEytEQEekbEyl3kStSekqk5IqUGo0mZJwnRUTkNnKziQJzMfKLilWOhohI35hIuYtc1dHT0D61K1IAEykiIjcK9vOFj0G6zc59RESuYSLlLnqsSKnZ+lzGRIqIPCg9PR3Dhg1DeHg4wsPDMWzYMFy9erXCx1y7dg3jx49HrVq1EBgYiCZNmmDBggXlbiuEQO/evWEwGPDFF18o/wQc5ONjYOc+IiKFMJFyFz1WpNRcjFfGRIqIPGjIkCE4ePAgNm3ahE2bNuHgwYMYNmxYhY+ZOHEiNm3ahOXLl+PYsWOYOHEiHn/8cXz55Zdltp07dy4MBoO7wneKpeEEO/cREbnEV+0AvBYrUs5hIkVEHnLs2DFs2rQJe/bsQbt27QAAixYtQvv27XH8+HE0atSo3Mft3r0bw4cPR5cuXQAADz/8MN577z38/PPPGDBggGW7X3/9FXPmzMG+ffsQFxdXaTz5+fnIl9fyA5B5/cOtwsJCFBY6nvTIj7nxsaEBUnfUK1l5Tu3XXWzFq2V6i1lv8QL6i1lv8QL6i9kT8dq7byZS7sKKlHOYSBGRh+zevRvh4eGWJAoA7rjjDoSHh2PXrl02E6mOHTti/fr1GDVqFOLj47Ft2zacOHEC8+bNs2yTk5ODBx54AO+88w5iY2PtimfWrFmYPn16mfs3b96MoKAgB59dieTk5FJfF2b7APDBzj0/I/cv7XXuuzFePdBbzHqLF9BfzHqLF9BfzO6MNycnx67tmEi5CytSzmEiRUQekpqaiujo6DL3R0dHIzU11ebj3nrrLYwZMwa1atWCr68vfHx88MEHH6Bjx46WbSZOnIgOHTqUqlBVZsqUKZg0aZLl68zMTNSuXRtJSUkIc+J1ubCwEMnJyejRowdMJpPl/o0ZB3Ei4yJuanwL+rSr4/B+3cVWvFqmt5j1Fi+gv5j1Fi+gv5g9EW+mnYUQJlLuYl2REgLQ2Bj5crEiRUReYNq0aeVWdqzt27cPAMqdvySEqHBe01tvvYU9e/Zg/fr1qFu3Lnbs2IFx48YhLi4O3bt3x/r16/H999/jl19+cShuf39/+Pv7l7nfZDK5dLFw4+OrB0vHuJZfrMmLJlefrxr0FrPe4gX0F7Pe4gX0F7M747V3v0yk3EVORoqLgexsICRE3XjsoYWKVFSU9P/ly+rFQES6Nn78eAwePLjCbRISEnDo0CFcuHChzPcuXbqEmJiYch+Xm5uL5557DuvWrUPfvn0BAC1atMDBgwfxxhtvoHv37vj+++/x119/oVq1aqUee++996JTp07Ytm2bU89LKXLXPjabICJyDRMpdwkMBIxGwGyWKj16SKS0VJG6ckU6d0ajerEQkS5FRUUhSv5QpgLt27dHRkYG9u7di7Zt2wIAfvrpJ2RkZKBDhw7lPkZu/ODjU7rprdFoRHGxtMDts88+i//85z+lvt+8eXP873//Q//+/Z15SoqSF+XNzC1SORIiIn1jIuUuBoOUkKSlSZWe+Hi1I6qcFipSkZHS/0JI505OrIiIFNakSRP06tULY8aMwXvvvQdA6sDXr1+/Uo0mGjdujFmzZmHgwIEICwtDYmIinn76aQQGBqJu3brYvn07li1bhjlz5gAAYmNjy20wUadOHdSrV88zT64C4VxHiohIEVxHyp3khEQvnfu0UJEymYDq1aXbnCdFRG62YsUKNG/eHElJSUhKSkKLFi3w8ccfl9rm+PHjyLBqHLR69WrcfvvtGDp0KJo2bYpXX30VM2bMwCOPPOLp8J3CoX1ERMpgRcqd5IREL537tFCRAqQqVHo6EykicruIiAgsX768wm2EKN0iPDY2FosXL3boODfuQ01ckJeISBlMpNxJTxUpIbRRkQKkROrECSZS3s5sBnbuBFJSgLg4oFMnzokj8oAwDu0jIlIEh/a5k54qUtnZUodBQBsVKYCJlDdbuxZISAC6dgWGDJH+T0iQ7qeyzGYYtm9HzR07YNi+XUpCiZwUHshmE0RESmAi5U56WpRXrkYZjUBQkLqxMJHybmvXAvfdB5w9W/r+c+ek+5lMlXY96fTt0QNt5syBb48eTDrJJdZD+4qLtTPkkIhIb5hIuZP1orxaZz0/Su3Fg5lIeS+zGXjySWko6Y3k+yZMYMVFxqST3EAe2icEcK2AVSkiImcxkXInHVWkDFqZHwUwkfJmO3eWTQqsCQGcOSNtV9Ux6SQ3CTAZ4ecrvf1ncp4UEZHTmEi5k54qUlpKpOSFNJlIeZ+UFGW382ZMOsmNuJYUEZHrmEi5k44qUpppfQ6UVKQuX1Y3DlJeXJyy23kzJp3kRmEBbDhBROQqJlLupKeKVFaW9L8WKlIc2ue9OnUCatWyPQ/PYABq15a2q+qYdJIbcVFeIiLXMZFyJx1VpAxarUhpaBFLUoDRCMybJ92+MZmSv547l+tJAUw6ya04tI+IyHVMpNxJTxUpLc2RkhOpwkJdJKHkoEGDgDVrgMjI0vfXqiXdP2iQOnFpDZNOciNLC3QmUkRETmMi5U46qkhZEiktVKQCAoCQEOk2h/d5p0GDgDlzSr7u3x84eZJJ1I3kpLNmzdL3M+kkF4VZFuVlIkVE5CwmUu6ko4qUptqfA5wnVRVY/2z9/VlZsWXQIODYMcuXAgD++INJFLkk3DJHis0miIicxUTKneSkJDsbKNL4m5WW5kgBTKSqgosXS27z51yxK1csNw0AcPWqWpGQl+DQPiIi1zGRcifrpETuiqdVWuraBzCRqgouXCi5zZ9zxazPVXlfEzmIzSaIiFzHRMqdTCYgMFC6rfV5UqxIkaexImU/63NV3tdEDmL7cyIi1zGRcjc5MdH4PCnOkSKPs66qXLkCFBerF4vWsSJFCisZ2qfxYedERBrmUiKVn5+vVBzeS05MtF6R0lLXPgCIipL+ZyLlvayrKsXFQHq6erFoHStSpDAO7SMicp1DidS3336LESNGoH79+jCZTAgKCkJoaCgSExMxY8YMnD9/XvEAz507hwcffBCRkZEICgpCq1atsH//fsv3hRCYNm0a4uPjERgYiC5duuDIkSOKx+E0vbRA12pF6vJldeMg9xCibFWFSbNtrEiRwiztzzm0j4jIaXYlUl988QUaNWqE4cOHw8fHB08//TTWrl2Lb7/9Fh9++CESExOxZcsW3HTTTXjkkUdwSaELovT0dNx5550wmUz45ptvcPToUbz55puoVq2aZZvZs2djzpw5eOedd7Bv3z7ExsaiR48eyNJKcwcdtEA3mM0wZGdLX2ilIsWhfd4tMxMoKJBuy2sk8Wdt2/UKVL78esKKFLlIHtqXU2BGoZnDaomInOFrz0YzZ87EG2+8gb59+8LHp2zudf/99wOQqkfz5s3DsmXLMHnyZJeDe+2111C7dm0sXrzYcl9CQoLlthACc+fOxfPPP49B19dUWbp0KWJiYrBy5UqMHTvW5RhcpoOKlG9OTskXTKTIE+SKSmgoUKcOcO4cq48VuX6+MuvUQY3ffmNFilwWGlDy9p+ZW4jIEH8VoyEi0ie7Eqm9e/fatbOaNWti9uzZLgVkbf369ejZsyf+9a9/Yfv27ahZsybGjRuHMWPGAABOnjyJ1NRUJCUlWR7j7++PxMRE7Nq1y2YilZ+fX2p+V+b1alFhYSEKCx0f5iA/przHGkND4QPAnJ6OYif27W6FhYWWREoEBKDIYAC0EGe1ajABEJcuochGPBWdd62r6rEbzp+HLwARHQ0RGQkfAEWpqRBuPh96Pe++Fy7AACCzbl3U+O03FF+4ALPOnoOtc6+3n4W38DX6IMTfF9fyi5CZV8REiojICXYlUmr5+++/sWDBAkyaNAnPPfcc9u7diyeeeAL+/v546KGHkJqaCgCIiYkp9biYmBicPn3a5n5nzZqF6dOnl7l/8+bNCAoKcjre5OTkMvc1S0tDfQB/HTiAYxs3Or1vdwq7nkjlBwTgW43E6Jubi74ADLm5+HbtWpgDAmxuW95514uqGnvcrl1oCyDNZMK13FzUBfDHjz/iRHy8YvFVRG/nvdfZs/CHlEgBQN7p00jWyN+qo2489znWFXHyqPBAE67lF7HhBBGRk+xKpORhc45YuHAhoqOjHX6cteLiYrRp0wYzZ84EALRu3RpHjhzBggUL8NBDD1m2MxgMpR4nhChzn7UpU6Zg0qRJlq8zMzNRu3ZtJCUlIcyJoW2FhYVITk5Gjx49YDKZSn3PZ+9e4KuvUD86GvX69HF43+5WWFiI/XPnAgD8a9RAH63EKASEvz8M+fnoeeutgNWQTllF513rqnrsPmfOAACq33wzqt18M/Ddd7g5IgIN3Pz7p8vzbjbD93rVXE6kArOy0Kd3b6CC1zmtsXXuMzU8f9TbycP7MplIERE5xa5E6osvvsD999+PQHlx2UqsXLkS165dczmRiouLQ9OmTUvd16RJE3z++ecAgNjYWABAamoq4uLiLNtcvHixTJXKmr+/P/z9yw5jMJlMLl1clfv46tUBAMasLBg1euFmuv6JsCE8XFsXlzVqAGfPwnT1qrS4sQ2u/tzUVGVjvz4fyicuDrj+d2xMS/PY34iuzntamvTBgsGArNq1AQCG/HyYcnO102XTATeee938HLwQF+UlInKN3UP73nrrLbsTozVr1jgdkLU777wTx48fL3XfiRMnUPf6p7L16tVDbGwskpOT0bp1awBAQUEBtm/fjtdee02RGFymg659lmYTWrsou55IseGEF5K7zkVHs7FIZeTGEpGRMAcGQoSGwpCVJd2vtb9Z0hWuJUVE5Bq72p9v3boVERERdu/0m2++QU25pbELJk6ciD179mDmzJn4888/sXLlSrz//vt47LHHAEhD+iZMmICZM2di3bp1OHz4MEaMGIGgoCAMGTLE5eMrQgdd++SKlGY69sl4ge295EQqJoaLL1fGOukEpHNmfT+Rk+QW6Jm5RSpHQkSkT3ZVpBITEx3aaceOHZ0K5ka333471q1bhylTpuDll19GvXr1MHfuXAwdOtSyzTPPPIPc3FyMGzcO6enpaNeuHTZv3ozQ0FBFYnCZHipSubnSDa19us0LbO8lV1lYkarc9XMlridSokYNGP78ky3QyWXyorysSBEROUexrn1FRUU4f/486tSpo9QuAQD9+vVDv379bH7fYDBg2rRpmDZtmqLHVYycnGi5IqW1xXhlvMD2XtYVKfnnfPkyIISuGih4xI0VKfl/VqTIReGcI0VE5BK7hvbZ48iRI6hXr55Su/MecnLCipTjrC+wybuUV5HKywPkpJ5K3FiRkhMpVqTIRSVD+5hIERE5Q7FEimywrkgJoW4sNrAiRR6Vn19SoY2JAYKCAHmdMP6sy2JFityEzSaIiFxj99C+W2+9tcLv58pVDSpNTk4KC6ULyAoWllWL5itSvLj2LnIC4OsLVKsmDeWrUQM4c0b6WbOyXZpckZKbTMj/syJFLippf85mE0REzrA7kTp69CgGDx5sc/heSkoKTpw4oVhgXiMkRLpQFEL6FF6DiRQrUuRR1hUWeT6UnEhxGGdZ8vm6/vcg5L8LVqTIRWHXF+TNYkWKiMgpdidSzZo1Q7t27fDoo4+W+/2DBw9i0aJFigXmNXx8gNBQaY5URkbJp8kawooUeZRcSbH+W+DP2jbr83XpEitSpJjwIA7tIyJyhd1zpDp27FhmcVxroaGh6Ny5syJBeR2Nt0DXfEUqM1MaFkne4cY5PwBb3dsihOV8CVakSGGWZhN5hRAancNLRKRldlek5s6dW+H369evj61bt7oaj3fS+KK8vvKCvFqrSFWrBhiNgNksDflSYJFn0gBWpOxn/SFCdDRw9GjJecvIkDodanC4MOmDPEeq0CyQV1iMQD+jyhEREekLu/Z5gpYrUkLAJA/t01pFyseHlQpvVF5Fiq3uyyefq5AQqbshIL2e+PmV/j6RE4L9jDD6SPMUObyPiMhxLiVSzZs3x5kzZ5SKxXtpuSKVlwefousdm7RWkQJYqfBGrEjZr7xzZTCwBTopwmAwWBpOcFFeIiLHuZRInTp1CoWFfPGtlJYrUtdjEgaD9Km31rAi5X04R8p+1gsXW+OivKQQriVFROQ8Du3zBC1XpOSYQkOloXRaw0qF92FFyn5y0nljt0/5a1akyEWWtaSYSBEROcylK+dOnTohMDBQqVi8l4YrUoasLOmGFof1AZw74404R8p+rEiRm1l37iMiIsfY3bWvPBs3blQqDu+ml4qUFrFS4V2Ki0t+ltZVFnloX0YGUFBQ0kyhqmNFitzMMrQvh4kUEZGjnEqkTpw4gW3btuHixYsoLi4u9b2XXnpJkcC8ioYrUpY5UuHhMKgcSrmYSHmXtDSpnT1Q8rMFgOrVS7e6j49XJz6tKW8YpPXXrEiRi8IC5WYTRSpHQkSkPw4nUosWLcKjjz6KqKgoxMbGwmAoufw2GAxMpMojJ1JarEjJyZ3WWp/LmEh5F7mCEhEBmEwl9/v4AJGR0vcvXWIiJStvGKT116xIkYssQ/s4R4qIyGEOJ1KvvPIKZsyYgf/+97/uiMc7yUmKBitSBiZS5Em25vwA0s/64kXOk7LGihS5WRi79hEROc3hZhPp6en417/+5Y5YvJeWK1JyTEykyBNszfkB2AK9PFWoItW3b18sW7YMufIC4eQRlq59bDZBROQwhxOpf/3rX9i8ebM7YvFeGq5I4XrXPqH1rn3Wc2tIvyqrSAFMpGR5eSUfdNiqSF265DV/F61atcIzzzyD2NhYjBkzBnv27FE7pCqB60gRETnP4aF9DRo0wIsvvog9e/agefPmMFnPcwDwxBNPKBac19BwRcqg9a59kZHS/0IAV66UfwFO+mGrwgIwkbqRfB5MJqBaNaDIqhlAVBRgMEhdENPSSjfu0KkZM2Zg7ty5+Oqrr7B48WJ07twZDRo0wKhRozBs2DDElFfFJJeFBVxvNpHLZhNERI5yOJF6//33ERISgu3bt2P79u2lvmcwGJhIlUeuSGVlSRc+Wlr4Vk6ktFqR8vWVOrqlp0sXlkyk9M3WnB+Aa0ndyLp6Z7ihp6avr/Qhw+XL0nZekEgBgNFoxIABAzBgwABcunQJ7733Hl588UU899xz6NOnD5544gncddddaofpVTi0j4jIeQ4nUidPnnRHHN5NTlKEAK5d09Z8JHlon5ZiulGNGiWJFOlbRRUpzpEqraJhkPL9ciLVrJnn4vKAvXv3YvHixVi1ahWio6MxYsQIpKSkoH///nj00UfxxhtvqB2i1+DQPiIi52moNOLF/P1LWj1rbXif1ptNABzy5U3sqUjx5yypqDGH9f1e0nDi0qVLePPNN9GsWTN06tQJly5dwurVq3Hq1ClMnz4d77//Pr788kssXLhQ7VC9itz+/Fp+EYqLhcrREBHpi12J1KRJk5CdnW33TqdMmYK0tDSng/I6BoNmF+XVfPtzgEO+vIk9c6T4c5bYU5Gy3k7nmjRpgg8++ADDhw/H2bNnsWbNGvTq1avUWoVt27bF7bffrmKU3kdekFcIICuf86SIiBxhVyI1b9485OTk2L3Td999F1evXnU2Ju8kJypaq0jJiZRW50gBrFR4E1ak7FfFKlLr16/HsWPH8PTTT6OGjTlfYWFh2Lp1q4cj827+vkYEmKRLAS7KS0TkGLvmSAkhcPPNN5f6ZLAijlSvqgyNVqTkeIRWu/YBvMD2FtnZgPyBTEVzpK5c0V5TFjVUsYpUhw4d1A6hygoLMCGvMB8ZuYWorXYwREQ6YlcitXjxYod3zFa1N9BiRaq42NJsghUpcjv5gj8wEAgJKft9OZEym6XmInLr+6qqilWkSD3hgSZczMpnRYqIyEF2JVLDhw93dxzeT4sVqWvXYBDXJxfrYY4UEyl9s54fVV51289P+jvJyJDmSVX1RKqiYZDW93tJRYrUwxboRETOcXjszIcfflju/UVFRZgyZYrLAXktLVakrsdS7OsLBASoHEwFmEh5h8oqLAB/1tYqasxhfT8rUuQiLspLROQchxOpyZMn49577y3Vle/3339H27Zt8emnnyoanFfRYkXqeiyFQUHlVwi0ghfX3qGyOT8A15KSmc0l58CeipTQf9vqVatWIT8/v8z9BQUFWLZsmQoRVR1cS4qIyDkOJ1K//PILLly4gObNmyM5ORnvvvsubr31VjRr1gwHDx50Q4heQk6kNFiRKgoMVDmQSli3xfaCC8YqixUp+6WlSXMYgZLk8kZyQpqXJy30rXPjxo1DRjmvj1lZWRg5cqQKEVUdHNpHROQcu+ZIWatXrx527NiBiRMnolevXjAajVi2bBkGDx7sjvi8hzy0T4sVqeBg+KkcSoXkC8miIuDqVaB6dVXDISfZU5HiWlIS+VxFRpYs5n2joCCpace1a9L2Wu68aQchRLmdYc+ePYtwLTfD8QLyorxsNkFE5BiHEykA+Oqrr7Bq1Sp06NABx48fx6JFi9C5c2fEx8crHZ/3YEXKeQEBJReMly4xkdIrVqTsV9n8KFl0dEki1aCB++Nyg44dOwIADAYDunXrBl/fkrcls9mMkydPolevXmqFVyVwaB8RkXMcTqTGjh2LpUuX4pVXXsHkyZNx4cIFjBo1Cs2bN8eCBQtw//33uyNO/dN4RUrzatQoSaRuvlntaMgZnCNlv8o69sliYoC//9Z1w4l+/frht99+gxACPXv2RIhVa3w/Pz8kJCTg3nvvVTFC7xcWeL3ZRB6bTRAROcLhROrHH3/ETz/9hJYtWwIAYmNjsXHjRrz77rsYNWoUEylbWJFyTY0awMmTHPKlZ/ZUWViRktiTdFp/X8ct0J999lnMmjUL8+fPx8iRI+Hv7692SFWOXJHi0D4iIsc43Gxi//79liTK2mOPPYb9+/crEpRX0nD7c91UpABeYOuZPVUWzpGS2DMM0vr7Oq5IyTp37oxLVn/fe/fuxYQJE/D++++rGFXVIM+R4tA+IiLHOJxIVfRpYaNGjVwKxqtpuP25bipSABMpvSoqAq5ckW6zIlW5KlSRkv3nP//B1q1bAQCpqano3r079u7di+eeew4vv/yyytF5N3btIyJyjsOJFDmJFSnX8AJb3+Sfm4+P1InOFus5UlW51X0VrEgdPXoUbdu2BQB8+umnaN68OXbt2oWVK1diyZIl6gbn5dhsgojIOUykPEWuSOXlAQUF6sYiY0WKPEW+0I+KAoxG29vJP+e8PCA72/1xaZW9zSa8qCJVVFRkGfGwZcsW3H333QCAxo0bIyUlRc3QvJ48tC+vsBj5RWaVoyEi0g8mUp5ivcaLVob3yRWpoCCVA7EDEyl9szcxCA6W2t0DVXuelL3tz72oItW4cWMsXLgQO3fuRHJysqXl+fnz5xFZURWTXBYSUNJ3Koud+4iI7MZEylN8faWLREA7iZRckWIiRe5mb2JgMPBnLYRj7c8Br6hITZ8+He+99x66dOmCBx54wNLUaP369ZYhf+QeRh8DQq8nUxzeR0RkP6cW5LVl2bJluPPOO1G/fn0ld+s9wsKk4UpamSelp4oU1xfSN3vn/ADSz/rMmar7s752TRraCNjfbOLqVWnIsJ+fW0Nzp06dOuHy5cvIzMxEdatFtx9++GEE6eE1SufCAkzIyitiC3QiIgcoWpEaMWIEmjZtiscff1zJ3XoPrXXu02tFqio3IdAre7vQAaxIyecqOLikim1L9epStRvwiuF9Qgjs378f7733HrKysgBIi/IykXI/y1pSHNpHRGQ3RROp4uJiHD9+HM2aNVNyt95Da5379FSRYhMCfXOkIlXV15KydxgkIA2F9JKGE//88w+aN2+OAQMG4LHHHrOsKTV79mw89dRTKkfn/cICObSPiMhRis+RSkhIwNixY5XerXfQUkWqoMAyfEgXFamQEEBew6yqVir0zJGKVFUfxmnv/CiZlzScePbZZ9GmTRukp6cj0KqT6MCBA/Hdd9+pGFnVIHfu49A+IiL72TVH6tChQw7vuGnTpvD1VXQKlv7JiZQWKlJWyZwuEim5CcHZs1Klol49tSMiRzhTkaqqiZQjFSnr7XRekdq9ezd27doFvxvmedWtWxfnzp1z23HT09PxxBNPYP369QCAu+++G2+//TaqVatm8zHXrl3Ds88+iy+++AJXrlxBQkICnnjiCTz66KOlttu9ezeef/55/PTTTzCZTGjVqhW++eabUomiVnAtKSIix9mV6bRq1QoGgwHCzrkpPj4+OHHiBG666SaXgvM68tA+LVSkrscggoMhKlrXR0vkRKqqXmDrGedI2a+KVqSKi4thNpddw+js2bMItV4+QmFDhgzB2bNnsWnTJgBSc4thw4Zhw4YNNh8zceJEbN26FcuXL0dCQgI2b96McePGIT4+HgMGDAAgJVG9evXClClT8Pbbb8PPzw+//vorfHy02Sw3zDJHiokUEZG97C4Z/fTTT6ghX+BUQAjBOVK2aKkiJccgJ3d6UNUvsPVKCMeqLFV9jpQjSaf1djqvSHXt2hVz587F+++/DwAwGAy4du0apk6dij59+rjlmMeOHcOmTZuwZ88etGvXDgCwaNEitG/fHsePH0ejRo3Kfdzu3bsxfPhwdOnSBYCUfL333nv4+eefLYnUxIkT8cQTT+DZZ5+1PK5hw4YVxpOfn4/8/HzL15nXP/AqLCxEYaHjCY78GHseG+wnJXhXswucOpYSHIlXK/QWs97iBfQXs97iBfQXsyfitXffdiVSiYmJaNCgQYVDHax17txZk0MXVKfBihQTKXK7jAxpTh7AOVL2cGQYpPV2Oq9IzZo1C3fffTeaNm2KvLw8DBkyBH/88QeioqKwatUqtxxz9+7dCA8PtyRRAHDHHXcgPDwcu3btsplIdezYEevXr8eoUaMQHx+Pbdu24cSJE5g3bx4A4OLFi/jpp58wdOhQdOjQAX/99RcaN26MGTNmoGPHjjbjmTVrFqZPn17m/s2bN7vUuTA5ObnSbc6lGAAYcfzkP9i48ZTTx1KCPfFqjd5i1lu8gP5i1lu8gP5idme8OTk5dm1nVyK1detWhw6+ceNGh7avMjRYkRJMpMjd5Av80FDAng9YqvrPuYpWpOLi4nDw4EGsXr0a+/fvR3FxMUaPHo2hQ4e67YO51NRURJdznqOjo5GammrzcW+99RbGjBmDWrVqwdfXFz4+Pvjggw8sSdLff/8NAJg2bRreeOMNtGrVCsuWLUO3bt1w+PBhm5WpKVOmYNKkSZavMzMzUbt2bSQlJSHMidfqwsJCJCcno0ePHjCZTBVuW3DwPD4/dRjB1WqgT5/bHD6WEhyJVyv0FrPe4gX0F7Pe4gX0F7Mn4s20s+jBbhCepKX253IMcnKnB1X9AluvHJ3zI/+c5UqWjheZdUoVrUgBQGBgIEaOHImRI0e6tJ9p06aVW9mxtm/fPgDSEMIbCSHKvV/21ltvYc+ePVi/fj3q1q2LHTt2YNy4cYiLi0P37t1RXFwMABg7dqzlubRu3RrfffcdPvroI8yaNavc/fr7+8Nf7k5qxWQyuXSxYM/jI0ICAADX8otUv5By9fmqQW8x6y1eQH8x6y1eQH8xuzNee/frcCJlNpuxZMkSfPfdd7h48aLlDUP2/fffO7rLqkNL7c/lGNw4iVtxTKT0ydEudNWrAz4+QHExcOUKEBfnvti0yNlmEzqvSKWlpVmqLmfOnMGiRYuQm5uL/v37o3Pnzg7ta/z48Rg8eHCF2yQkJODQoUO4UM55u3TpEmJsnP/c3Fw899xzWLduHfr27QsAaNGiBQ4ePIg33ngD3bt3R9z139mmTZuWemyTJk3wzz//OPRcPCWMXfuIiBzmcCL15JNPYsmSJejbty+aNWtW4ad2dANWpFxT1efO6JWjiYGPDxAZKf2cL12qWolUQQFw9ap029GhfZcuScmnRrvC2XLkyBEAQP369dGwYUOsXr0avXr1QnZ2Nnx8fPC///0Pa9aswT333GP3PqOiohAlv15UoH379sjIyMDevXvRtm1bAFJjpYyMDHTo0KHcx8iNH27svmc0Gi0fLCYkJCA+Ph7Hjx8vtc2JEyfQu3dvu5+HJ1nWkcorUjkSIiL9cDiRWr16NT799FO3dVHyahqsSHGOFLmdoxUpQPpZy4lUVSKfK19fqTJnD/nvwmwG0tJKPnDQiZdeegmANLd23bp16NevH/r06YMPPvgAAPD444/j1VdfdSiRsleTJk3Qq1cvjBkzBu+99x4AqQNfv379SjWaaNy4MWbNmoWBAwciLCwMiYmJePrppxEYGIi6deti+/btWLZsGebMmQNAGi749NNPY+rUqWjZsiVatWqFpUuX4vfff8eaNWsUfx5KsF5HqrKhjUREJHE4kfLz80ODBg3cEYv302JFiokUuZujFSmg6v6s5USqRg37K0smExARISVRFy/qLpE6cOAAAKk6dOedd+L999/HuHHjLBWfxx9/HHfccYfbjr9ixQo88cQTSEpKAiAtyPvOO++U2ub48ePIsHrdXr16NaZMmYKhQ4ciLS0NdevWxYwZM/DII49YtpkwYQLy8vIwceJEpKWloWXLlkhOTkb9+vXd9lxcERYoXQ6YiwVyCswI9ucUaiKiyjj8Sjl58mTMmzcP77zzDj+xcpR1RUoIQM3zp+f251lZQH6+7oYwVVnOVqSAqreWlDNJp7x9Wpr0+Bvm5Whdenq65XZISAiCg4MRERFhua969erIyspy2/EjIiKwfPnyCre5cTH62NhYLF68uNJ9P/vss6XWkdKyQJMRvj4GFBULZOYVMpEiIrKDw6+UP/zwA7Zu3YpvvvkGt9xyS5muFmvXrlUsOK8jJy1mM5CTAwQHqxeL3P5cT3OkqlUDjEbp/F2+7NiFOanH0S50QNWdD+dM0ilvf+yY7htOyPghnecZDAaEB5pwJbsAGbmFiAvnWpBERJVxOJGqVq0aBg4c6I5YvF9wcEk3ssxMdRMpPXbt8/GRLrAvXJAusJlI6YOj6yIBVXdonysVKUDXLdCHDh0Kk8mEvLw8PPLIIwi+/vqYn5+vcmRVR9j1RCozlw0niIjs4XAiZc9wBrLBYJCqUlevShUhNbuRWXftK9RRu9saNUoSKdIHZypSVT2RcqYiZf14HRkyZAhWrFiB8PBwmEwmPPjgg2W2eeihh1SIrOqRW6BnsgU6EZFdOAja08LDpURK7c591nOkrlxRNxZHVNULbL3KyytJ2jlHqnLOJJ3W2+uwIjV//nysWLEC8+fPt6wjReoIC5AuCbiWFBGRfeyarX/rrbeWmhBcmY4dO+LcuXNOB+XV5DlJanfuk+dI6e3ChYmUvsg/J5NJmuNmr6o6R6oKVqRIOywVqTwmUkRE9rCrInXw4EH8+uuvpTopVbY9x7XbICcualakhNBn1z6AiZTeWCcGjjQQqKo/5ypYkSLtCLcM7eMcKSIie9g9tK9bt25lWsDa4q6OS7NmzcJzzz2HJ598EnPnzgUgtaWdPn063n//faSnp6Ndu3Z49913ccstt7glBpdpoSKVkyN1vrOORy+qaqVCr5ztQicnUleuSM1Zqkqre2ebTbAiRQoICyhZlJeIiCpnVyJ18uRJh3dcq1Ythx9TkX379uH9999HixYtSt0/e/ZszJkzB0uWLMHNN9+MV155BT169MDx48cRqsWOdFqoSMnH9vFRt3OgM6pqpUKvnE0M5ITZbJbmFNpZDde14uKS32tHE09WpEgB8qK8HNpHRGQfuxKpunXr2rUzIYRbqlHXrl3D0KFDsWjRIrzyyiuljjd37lw8//zzGDRoEABg6dKliImJwcqVKzF27FjFY3GZFipS8rHDwtRdFNgZTKT0xdmKlJ+f9PuZmSn9rKtCIpWWVlIpln/P7SUnUjk5wLVrQEiIsrFRlSAP7WNFiojIPg537Rs2bBgWLFiAkBveqE+dOoVhw4Zh586digUne+yxx9C3b1907969VCJ18uRJpKamIikpyXKfv78/EhMTsWvXLpuJVH5+fqk5XJnXKzSFhYUodKIVuPwYex7rExwMIwBzejqKVWo7brhyBb6QFuN1JHYtMFSvLsV+8aLuYrdWVWL3SUmRft+johz+ffetUQOGzEwUpaRA3HSTM6GWoenzfu4cTABE9eooMhjKLEtQYex+fvANCoIhJweF584BCp0vJdmKX5M/iypKHtrH9udERPZxOJE6evQomjdvjuXLl+POO+8EIFWBnnjiCfTo0UPxAFevXo0DBw5g3759Zb6XmpoKAIi5YdhQTEwMTp8+bXOfs2bNwvTp08vcv3nzZgQFBTkda3JycqXbNExNRVMAZ48cwcGNG50+litqHDyIDgAyAWy7HrM9sWtB6OnTuAtAYUqKJWa9xF4eb4/91oMHURvAsbQ0/OXg73snX19EADjw7bdIUbiCq8XzHvXbb7gTwLXgYHxfwbmyFXv30FAE5+Rg9xdfIL1xYzdF6bob48/JyVEpErqRpdlEHptNEBHZw+FE6qeffsILL7yAu+66C5MnT8Yff/yBTZs2Yd68eRg1apSiwZ05cwZPPvkkNm/ejICAAJvb3TicsLIhhlOmTMGkSZMsX2dmZqJ27dpISkpyah2TwsJCJCcno0ePHjCZTBVu63PqFLBiBWqHhSG+Tx+Hj6UEQ24uACC0Vi306NHD7tg14cIF4MknYbp2DT26dkXy1q36id2KI78zWuNI7Ma33wYANO7cGY0c/H03LloEHD+OW+vWhVDob0XL591w7RoAILhePfQp5/lWFruxbl3gwgV0qF9fsfOlJFvxZ6q9ph5ZcEFeIiLHOJxI+fr64tVXX4W/vz/+7//+D76+vti+fTvat2+veHD79+/HxYsXcdttt1nuM5vN2LFjB9555x0cP34cgFSZiouLs2xz8eLFMlUqa/7+/vD39y9zv8lkcuniyq7HX5/r4XPtGnzUupC7/gmwT3i4JV5Xn7vHxMYCAAxCwJSVBUBHsZfD62O/PpfNNz5eWkvKEdfnVfmmpTn+2Epo8rxfXxjbJza2wtcGm7Ff/9twx/lS0o3xa+7nUIXJC/IykSIiso/DPYULCwsxefJkvPbaa5gyZQrat2+PgQMHYqMbhql169YNv/32Gw4ePGj516ZNGwwdOhQHDx7ETTfdhNjY2FJDRQoKCrB9+3Z06NBB8XgUIVe8tNBsQm+tzwHA17ek8QAbTmifs137gKrXWMTZxhwytkAnF8lD+7Lyi2Autm+5EyKiqszhilSbNm2Qk5ODbdu24Y477oAQArNnz8agQYMwatQozJ8/X7HgQkND0axZs1L3BQcHIzIy0nL/hAkTMHPmTDRs2BANGzbEzJkzERQUhCFDhigWh6Lk5EUL7c/1thivrEYNIC0NhsuX1Y6EKuJKO2+g6iVSriSd1o9jC3RyUmhASXUwK68Q1YL8VIyGiEj7HK5ItWnTBgcPHsQdd9wBQJqf9N///hd79uzBjh07FA+wMs888wwmTJiAcePGoU2bNjh37hw2b96szTWkAFaklFDVLrD1Ki1NSqYAx9t5Wz+mqiTMciLFihSpxM/XB4EmIwAgM5cNJ4iIKuNwRerDDz8s9/5WrVph//79LgdUmW3btpX62mAwYNq0aZg2bZrbj60IVqRcd/0C23D5MlCnjsrBkE3yBX1EhHNzduRFeatKwixXkliRIhWFB5qQW2jmWlJERHawqyKVnZ1t187kBg72bl8lycnLtWsli296mt4rUlXtAluvXE0MqlrlkRUp0oCwwOsNJ/KYSBERVcauRKpBgwaYOXMmzp8/b3MbIQSSk5PRu3dvvPXWW4oF6HWsq0DXu855nJdUpKrMkC+9cjUxsE6kRBWY+M6KFGlAOFugExHZza6hfdu2bcMLL7yA6dOno1WrVmjTpg3i4+MREBCA9PR0HD16FLt374bJZMKUKVPw8MMPuztu/fL3l/7l50uVoWrVPB+D3itS8tC+qlKp0CulKlJ5eVLL/uBgZeLSomvXLMsSuJxIpaUBhYWaboFO2hV2veEEh/YREVXOrkSqUaNG+Oyzz3D27Fl89tln2LFjB3bt2oXc3FxERUWhdevWWLRoEfr06QMfH4f7V1Q94eHSRaZa86RYkSJPcLUiFRxc8qHDpUvenUjJSWdgoPPPs3p1wGiUhgxfugTExysXH1UZlkV5ObSPiKhSDjWbqFWrFiZOnIiJEye6K56qQU6k1Orcx4oUeYKr6yIZDNLP+uxZKTFISFAsNM2xbn1uMDi3Dx8f6VynpEj7YyJFTigZ2seufURElWH5SA1yJYgVKefIFakrV9SNgyrm6rpIQNWpPrqadMrkx3OeFDkpLED6fJVD+4iIKmdXRWrSpEl273DOnDlOB1NlyJUgNSpSZrM0H8M6Dr2xvriuCk0I9EqJ5KCqdGhUIum0fjw795GTOLSPiMh+diVSv/zyS6mv9+/fD7PZjEaNGgEATpw4AaPRiNtuu035CL2RmovyWlfBdF6RMhQVwcRW+9qlZEXK2xMppStSTKTISXIixYoUEVHl7Eqktm7dark9Z84chIaGYunSpahevToAID09HSNHjkSnTp3cE6W3UXNRXvmYcvfAQh2+Wfr7A6GhQFYW/NSaZ0aVUyI5qCqJlNIVKQ7tIyfJXfvY/pyIqHIOz5F68803MWvWLEsSBQDVq1fHK6+8gjfffFPR4LyWmhUpvTeakF2/wPZXa54ZVUyJdt5A1Zkj5WqHQxkrUuQiS7OJPDabICKqjMOJVGZmJi6U8yZ98eJFZKm1wKzeaKEipddhfbLrc2dYkdIoJdp5A1VnjpSra27JWJEiF4UFstkEEZG9HE6kBg4ciJEjR2LNmjU4e/Yszp49izVr1mD06NEYNGiQO2L0PqxIuY4VKW1Top03UPWG9rEiRSrj0D4iIvs5tI4UACxcuBBPPfUUHnzwQRRen1/j6+uL0aNH4/XXX1c8QK/EipTrrl9gsyKlUUo1T6gqiRQrUqQR4UFSIpVfVIy8QjMCTEaVIyIi0i6HE6mgoCDMnz8fr7/+Ov766y8IIdCgQQMEuzJ8p6phRcp1rEhpm1KJQVWYI1VYCKSlSbddPV/W60gVF0uL9BI5IMTPFwaDtLJEZl4hEykiogo4nEjJgoOD0aJFCyVjqTpYkXKdXJFiIqVNSg1Vk+dIXb0qJRwmk2v70yK52mY0AhERru1LPt9FRdI5c3V/VOX4+BgQ6u+LzLwiZOYWITpU7YiIiLSLH1eqgRUp18kVKQ7t0yalKlIRESVVFW+tSslJZ40arleQ/PwAuaMq50mRk+ThfWw4QURUMSZSamBFynXXP2kPPn8ehu3bAbNZ5YCoFKUqUj4+QGSkdNtb50kpNZ9MZj28j8gJloYTeUykiIgqwkRKDaxIuWbtWmDMGABA8MWL8O3RA0hIkO4nbVAyOfD2eVJKLcYrk/fDihQ5ybKWFCtSREQVYiKlBjmJKSgA8vM9e2y9V6TWrgXuu6/sp+3nzkn3M5nSBiWTA29fS8pdFSkmUuQktkAnIrIPEyk1hFrN3vV0VUrPFSmzGXjySamd1I3k+yZM4DA/LXBHRcpbEyl3VaQ4tI+cJC/Km5lXpHIkRETaxkRKDT4+JcmUp+dJ6bkitXMncPas7e8LAZw5I21H6iksBK5ckW4rkRx4eyLFihRpDIf2ERHZh4mUWuSKECtS9ktJUXY7cg95LpOPjzLttzlHyjGsSJGL5KF97NpHRFQxJlJqUavhhHw8PVak4uKU3Y7cw7qdt1GBxTy9fY6UUh0OZaxIkYvCAtm1j4jIHkyk1KJWC3T5eHqsSHXqBNSqBRgM5X/fYABq15a2I/UoPVStqgztY0WKNKJkaB/nSBERVYSJlFrUqEjl5UmdAgF9JlJGIzBvnnT7xmRK/nruXGWqIOQ8pYeqeXMiVVzMOVKkOXKzCQ7tIyKqGBMptahRkbI+VkiI546rpEGDgDVrgJo1S98fHy/dP2iQOnFRCXdVpLxxjtTVq0DR9U/9lTpfcgKbnS39I3JQOIf2ERHZhYmUWtSoSMnHCg3Vd9Vm0CDg1CkUJScjTz6PS5cyidIKpStS8hypy5elCo43kc9VtWqAv78y+wwJAQICpNsc3kdOYLMJIiL7MJFSi5oVKT02mriR0QiRmIj0Jk2krw8dUjceKqF0RUpOpMxmqYLjTZQ+V4A0zJXzpMgFYVbtz0V56/YREREAJlLqUbMipcf5UTZcvekm6cYvv6gbCJVQunmCv3/J34u3zZNSunonk/fHeVLkBHloX7EAsgu4wDkRkS1MpNTCipQiMurVk24cPKhqHGRF6XbegPfOk3JHRcp6f0ykyAn+vj7wM0qXBxzeR0RkGxMptbAipQhLInX0qNSVkNSndEUK8N61pNxdkeLQPnKCwWCwdO7LZCJFRGQTEym1sCKliLyoKIjISGn+zJEjaodDQrinyuKtLdBZkSKNsp4nRURE5WMipRZWpJRhMEC0bCnd5jwp9WVklKxVxkSqcqxIkUaxcx8RUeWYSKmFFSnFiFatpBucJ6U+OTEICytpwa0EzpFyDCtS5KKStaSKVI6EiEi7mEipRU6kWJFymWjRQrrBipT63JUYcI6UY1iRIhfJQ/tYkSIiso2JlFrkqlBmpjSvxBO8vSL166/SXClSj7sSA28f2seKFGlMWACbTRARVYaJlFrkqpAQwLVrnjmml1akcPPN0jCy7Gzgr7/UjqZqc1dFyhsTqexs6R/gvorUlStAEYdmkeNKhvYxkSIisoWJlFoCAgBf6RM/jw3vk4/jZRUp+PoCHN6nDe6uSHnTHCk56QwIAEJDld13RATgc/3l3ZuST/IYDu0jIqocEym1GAyebzghH8fbKlIA0Lq19D8bTqiLc6TsZ32uDAZl9200liSfnCdFTpC79mXmsqJJRGQLEyk1eboFurdWpABAnifFipS63F2Rys0tGQ6nd+46VzJ5v5wnRU7g0D4iosoxkVITK1LKYUVKG9xVkQoJAfz9pdveUpVy17mSyftlRYqcEBbIZhNERJVhIqUmT1akiou9O5Fq3lyaE3LhApCSonY0VZd80a50lcVgKBne5y3zpFiRIg2zVKSYSBER2cRESk2erEhlZ5e0WffGoX1BQUCjRtJtVqXU46523oD3de7zVEWKiRQ5QZ4jxWYTRES2MZFSkycrUvIxfH2BwED3H08NnCelrry8kg8F3FFl8bZEylMVKQ7tIyfIXfuyC8woMherHA0RkTYxkVKTJytS1ovxKt0hTCvkeVJMpNQhX7D7+bln+Ki3JVKsSJGGyQvyAkBWHjv3ERGVh4mUmtSoSHnj/CgZG06oy53tvAHOkXIUK1LkAl+jD4L9jAA4vI+IyBYmUmpSqyLlreShfX/+6blOiFTCnfOjAO+rSLn7fLEiRS4KYwt0IqIKMZFSEytSyoqKAmrVkm4fOqRuLFWRu4eqeVMiVVQEXLki3fZERUpuNEPkgJLOfRzaR0RUHiZSamJFSnlsOKEedw9V86ZESn4OPj5AZKR7jiGfr8JC4OpV9xyDvBo79xERVYyJlJrkRIoVKeVwnpR63F2R8qY5UvK5iooCjEb3HCMgoOTvnfOkyAkc2kdEVDEmUmqSq0OsSCmHFSn1sCJlP3efKxnnSZELwgKlzn1clJeIqHxMpNTEipTy5IrUkSNAQYG6sVQ1npojdfWqNFxNz9x9rmTs3Ecu4NA+IqKKMZFSkxrNJry9IpWQICWLBQXAsWNqR1O1uLvKUr26NKcI0P/wPk9VpOT9syJFTgjn0D4iogoxkVKTXB3KzXX/J+zy0D5vr0gZDBzepxZ3V1mMRiAiQrqt90TKUxUpDu0jF8hzpDLYtY+IqFxMpNQUGlpy293zpKpKRQpgwwk1mM0lc5fcWWXxlnlSnq5IcWgfOSEsgHOkiIgqwkRKTSYTEBQk3XZ3IlVVKlIAK1JqSEsDioul23J3PXfwlkSKFSnNSE9Px7BhwxAeHo7w8HAMGzYMVytpF3/t2jWMHz8etWrVQmBgIJo0aYIFCxaU2iY1NRXDhg1DbGwsgoODceutt2LNmjVufCbK49A+IqKKMZFSm6fmSVXVihQXIvUMOTGIjJQ+IHAXb0mkWJHSjCFDhuDgwYPYtGkTNm3ahIMHD2LYsGEVPmbixInYtGkTli9fjmPHjmHixIl4/PHH8eWXX1q2GTZsGI4fP47169fjt99+w6BBg/Dvf/8bv+joA56SoX1MpIiIysNESm2eWpS3KlWkmjQB/Pyk53zypNrRVA1yYuDuCou3rCXFipQmHDt2DJs2bcIHH3yA9u3bo3379li0aBG++uorHD9+3Objdu/ejeHDh6NLly5ISEjAww8/jJYtW+Lnn38utc3jjz+Otm3b4qabbsILL7yAatWq4cCBA554aoqwVKQ4R4qIqFy+agdQ5Xm6IlUVEimTCWjWDDhwQKpK3XST2hF5PzkxcHeFxRsqUkJ47nyxIlWh3bt3Izw8HO3atbPcd8cddyA8PBy7du1Co0aNyn1cx44dsX79eowaNQrx8fHYtm0bTpw4gXnz5pXa5pNPPkHfvn1RrVo1fPrpp8jPz0eXLl1sxpOfn4/8/HzL15nXPwArLCxEoRMNieTHOPNYAAi6foWQmefc8R3larxq0FvMeosX0F/MeosX0F/MnojX3n0zkVKbJypShYVSZ0CgagztA6R5UgcOSPOkBg1SOxrv56mKlDckUlevlqxx5qmKVFaW9BoQGOje4+lMamoqosv5GURHRyM1NdXm49566y2MGTMGtWrVgq+vL3x8fPDBBx+gY8eOlm0++eQT/Pvf/0ZkZCR8fX0RFBSEdevWoX79+jb3O2vWLEyfPr3M/Zs3b0aQPJ/WCcnJyU49Lq8IAHxRUFSMLzZshJ/R6RAc4my8atJbzHqLF9BfzHqLF9BfzO6MNycnx67tmEipzRMVKeskraokUuzc51meGqomJ1J6Htonn6uwMCAgwL3HCgsD/P2B/HzpuHXruvd4GjFt2rRyExJr+/btAwAYDIYy3xNClHu/7K233sKePXuwfv161K1bFzt27MC4ceMQFxeH7t27AwBeeOEFpKenY8uWLYiKisIXX3yBf/3rX9i5cyeaN29e7n6nTJmCSZMmWb7OzMxE7dq1kZSUhDAnXrsLCwuRnJyMHj16wOTE3EUhBKb8nIxiAXTo0g3Rof4O78MRrsarBr3FrLd4Af3FrLd4Af3F7Il4M+0scDCRUpsnKlLyvgMD3dsIQEvYuc+zPNU8QZ4jpeeKlKeqd4C0rlp0NHDmjHTcKpJIjR8/HoMHD65wm4SEBBw6dAgXypk/dunSJcTY+F3Ozc3Fc889h3Xr1qFv374AgBYtWuDgwYN444030L17d/z111945513cPjwYdxyyy0AgJYtW2Lnzp149913sXDhwnL37e/vD3//ssmKyWRy6WLB2cebiwUC/YzIzjdj99/pGHhrLRh9bCeYFe1n78k0XMzKQ3RoANrWi6hwP7bidXQ/SsVjD1d/Rp6mt3gB/cWst3gB/cXsznjt3a+mE6lZs2Zh7dq1+P333xEYGIgOHTrgtddeKzVuXQiB6dOn4/3330d6ejratWuHd9991/LmpXmeqEhVpflRspYtpYvIc+eki265kkHu4emKlJ4TKU/Nj5LFxEiJVBWaJxUVFYUoO9rwt2/fHhkZGdi7dy/atm0LAPjpp5+QkZGBDh06lPsYeb6Sj0/pXk1GoxHF15cAkIeEVLSN1m06nILpG44iO98MAHhqzSG8mXwCU/s3Ra9mcQ7vJyUjz3JfXHiA7vdDRARovGvf9u3b8dhjj2HPnj1ITk5GUVERkpKSkJ2dbdlm9uzZmDNnDt555x3s27cPsbGx6NGjB7KyslSM3AGerEhVlWF9gLTYcYMG0m0O73M/T1WkrIf26eSCtAxPnSuZfBx27iujSZMm6NWrF8aMGYM9e/Zgz549GDNmDPr161fqA7vGjRtj3bp1AICwsDAkJibi6aefxrZt23Dy5EksWbIEy5Ytw8CBAy3bN2jQAGPHjsXevXvx119/4c0330RycjLuueceNZ6qQzYdTsGjyw+USjYAIDUjD48uP4BNh1Oq9H6IiGSaTqQ2bdqEESNG4JZbbkHLli2xePFi/PPPP9i/fz8AqRo1d+5cPP/88xg0aBCaNWuGpUuXIicnBytXrlQ5ejvJiRQrUsrj8D7P8VRFSq4ymM3u73TpLp46VzL5OFWoIuWIFStWoHnz5khKSkJSUhJatGiBjz/+uNQ2x48fR4bV79vq1atx++23Y+jQoWjatCleffVVzJgxA4888ggAaUjIxo0bUaNGDfTv3x8tWrTAsmXLsHTpUvTp08ejz89R5mKB6RuOorwV+OT7pm84CnNxxWv0eet+iIisaXpo343kN7KIiAgAwMmTJ5GamoqkpCTLNv7+/khMTMSuXbswduzYcvejpRazhuBg+AIovnoVZje1cTSkpUnHCA0tcwy9tby0VlnsPi1awPjZZyg+cMBt59ZZXnXehYDvhQswACiMiJC6RLqLjw98Q0NhyMpC4fnzQEiIQw/Xwnn3SUmBEYA5KgrFDsThbOw+UVHS8VJSHDqe0mzFr/bfQEREBJYvX17hNuKGhb1jY2OxePHiCh/TsGFDfP755y7H52l7T6aVqdhYEwBSMvLw0Ic/IaqC5hOXs/Id3k9xcTHOn/fBls8OWYZFOrMfV+LZezIN7etH2tyOiMiabhIpIQQmTZqEjh07olmzZgBgaU9746TgmJgYnD592ua+tNRiNv6vv3A7gLRTp/Djxo1OH7siCbt2oSWA1Jwc7LNxDL21vLRmK/boggK0B5D944/43k3n1lXecN6Nubnod729/re//ALz77+79bjdg4IQnJWFPRs2IK1JE6f2oeZ5v/233xAP4PDFizjlxO+lo7HfdOUKmgNIOXgQ+zXwd3Bj/Pa2mCXPuJhlO9mw9uNfVxQ5Xtn9+GD/Zdut590dj73Pn4gI0FEiNX78eBw6dAg//PBDme/d2Ka2sta1Wmoxa/D1BV5/HZFGo9uGfPj89hsAIPbmm8scQ28tL61VGvuttwL/938IOXcOfRITgeBgzwdpg1ed97/+AgCIoCD0vPdetx/fWLcucOEC2jdoAOHg34wWzrvxtdcAALfcdReaOhC/s7EbMjKAjz5CvK8vYlQcVmYrfntbzJJnRIfa15J/2B11kRBl+zX11OVsfLzH9gea5e3HbDbj2LGjaNKkKYxGo9P7cSUee58/ERGgk0Tq8ccfx/r167Fjxw7UqlXLcn9sbCwAqTIVF1fSbefixYs2W9cCGmsxGykNITBkZbnvwu56cw6f6tXhY+MYemt5ac1m7LVrAzExMFy4ANPvvwN33OH54CrhFec9PR0AYIiO9sxzuT7nx/fqVafb+at63q93HPSNj3cqfodjj48HAPhcvGjz79+Tboxfr7//3qptvQjEhQcgNSOv3PlEBgCx4QGYdvctFbYMNxcLbDl2waH9FBYWYuPVI+jToa7l98KZ/bgST9t6ETb3QUR0I003mxBCYPz48Vi7di2+//571KtXr9T369Wrh9jY2FJDRQoKCrB9+3abrWs1x5Ptz6tS1z6ZvDAvG064j6e70Ol9LSm1uvax2QTZwehjwNT+TQFIyYU1+eup/ZtWuu6SnvYjs2c/RETWNJ1IPfbYY1i+fDlWrlyJ0NBQpKamIjU1FbnX52MYDAZMmDABM2fOxLp163D48GGMGDECQUFBGDJkiMrR28m6/blwU7cgeehMVevaB5QkUmyB7j6e7kKn57WkcnMBeWkGT3ftu3wZKCryzDFJ13o1i8OCB29FbHjpYW6x4QFY8OCtdq+3pJf9mIwGzB9q/36IiGSaHtq3YMECAECXLl1K3b948WKMGDECAPDMM88gNzcX48aNsyzIu3nzZoSGhno4WifJVaKiIukiy4VmFzZV5YoUW6C7n6cXmNVzIiWfKz8/z32wERUlLU4tBHDliud+TqRrvZrFoUfTWOw9mYaLWXmIDpWGvTlasdHyfv66dA3T1h9BoVkgOsx2xz8iIls0nUjd2HK2PAaDAdOmTcO0adPcH5A7hISUXORkZronkWJFCvjtNylZ9dX0r7w+yUPVPFVhkYf2Xb7smeMpyfpcVdAQR1FGo3TOLl2Sjs9Eiuxk9DEo0gpcq/tpXz8Sv53NwCc/n8GiHSdx2zDOjyIix2h6aF+VYDC4f55UVa5I1a8vJat5ecDx42pH451YkbKfp8+VjPOkiMo1upM09/rbo6k4fSVb5WiISG+YSGmB9Twpd6jKFSkfH6BlS+k250m5h6crUnpOpDzdaEIm/2zk4xMRAODmmFB0vrkGhAAW/3hK7XCISGeYSGmBpypSVTGRAjhPyt3YbMJ+nj5XMlakiGwac70q9enPZ5CRW6hyNESkJ0yktMCdFSl57hVQNYf2Aezc525qtT/PzQVycjxzTKWoVZGSj8eKFFEZHRtEoVFMKHIKzFi19x+1wyEiHWEipQXurEjl5pa0PGZFyn0t5quqwkIgLU267akqS2io1PUO0F9VSq2KFIf2EdlkMBgsc6WW/HgKheZilSMiIr1gIqUF7qxIyfs0GIDgYOX3rwfNmknd+tLSgDNn1I7Gu8iJjI8PEOl6Ny27GAz6Hd6ndkWKQ/uIyjWgVTyiQvyRmpmHjb+lqB0OEekEEyktkBMpd1SkrDv2+VTRH7e/P9BUWtGew/sUJl+Y16jh2d8vvSZSrEgRaZK/rxHD29cFACza+bddy68QEVXRK2uNkYf2ubMiVVXnR8nYcMI91Kqw6HUtKVakiDRr6B114e/rg8PnMvHTyTS1wyEiHWAipQWeqEhV1flRMjaccA+1Kix6rEiZzSWJn5oVKX7STlSuiGA/3HtbLQDABztPqhwNEekBEyktcGeziaq8GK81VqTcQ60Kix4TqcuXpSTGYCipqHmKnEgVFLhvvToiLzC6o9R04rvfL+DvS9dUjoaItI6JlBZ4otlEVa9IyYnU6dNAerqqoXgVVqTsJyedkZFS8xNPCgyUuh1ax0FEZdSvEYJujaMhBPDRj6xKEVHFmEhpAStS7letGpCQIN3m8D7lcI6U/eSk09PnSsZ5UkR2kVuhr9l/FunZBSpHQ0RaxkRKC1iR8gzOk1IeK1L2k5NOT58rGTv3Edml/U2RaBoXhrzCYqzkAr1EVAEmUlrAipRnyIkU50kpR60qix4TKVakiHTBYDBgTOfrC/TuOoX8IrPKERGRVjGR0gJWpDyDDSeUp1aVRY+JlFrDIGXycVmRIqpU3+bxiAnzx6WsfGz4lQv0ElH5mEhpgVwtysqSWiQriRWpEnJF6tgxIC9P3Vi8gRDqDe2T50hdvQoUFnr22M5S61zJ5OOyIkVUKT9fHwzvkAAA+IAL9BKRDUyktMC6WnRN4XarrEiVqFlT6phmNgOHD6sdjf5ZJzGeTg4iIqQ24gBw5Ypnj+0sVqSIdGVo27oINBnxe2oWdv2lk9cZIvIoJlJa4O8P+PlJt5WeJ8WKVAmDgQ0nlCRXNsLCgIAAzx7baJSSYkA/w/u0UpFiIkVkl/AgE+5vIy3Qu2jn3ypHQ0RaxERKK9w1T4oVqdI4T0oxBrWbJ+htnpRWKlIc2kdkt5F31oPBAGw7fgl/XMhSOxwi0hgmUlrhrs598v6YSElYkVKO2hUWPa0lpeZ8MhkrUkQOS4gKRo8m0ocQXKCXiG7EREor3F2R4tA+iVyR+vVX5Rt7VDGsSDkgMxPIz5duq5VIyT+nzEw2WyFywJjONwEAPj9wDleu5ascDRFpCRMprXBHRcpsljoBAqxIyRo1AgIDgexs4K+/1I5G39SusOgpkZLPVUgIEBSkTgzh4SVzMTm8j8hubepWR8ta4SgoKsbHe06rHQ4RaQgTKa1wR0XKugMgK1ISoxFo0UK6zXlSrmFFyn5qz48CpGYrbIFO5DCDwYDRnaSq1Me7TyOvkKMZiEjCREor5ERKyYqUvC8/P893VdMyNpxQhEHtipSe5kiptXDxjThPisgpfZrFoma1QFzJLsCXB8+pHQ4RaQQTKa1wx9A+tj4vnzsbTpjNwLZtwKpV0v/ePA+LFSn7qX2uZOzcR+QUX6MPRlgW6D3JBXqJCAATKe1wx9A+tj4vn3VFSsk3w7VrgYQEoGtXYMgQ6f+EBOl+L2SQExjOkaqcFob2AaxIEbng321rI9jPiD8uXsP2Ezp43SEit2MipRWsSHlO8+aAj4/0qXxqqjL7XLsWuO8+4OzZ0vefOyfd743JlNrJgZ4SKbWHQcpYkSJyWliACf++vQ4A4MMf2AqdiJhIaQcrUp4TFCR17wOUmSdlNgNPPll+dUu+b8IErxrm55OfD4PcEVILc6S0PsxG7aRTJh+fFSkip4y8MwE+BmDnH5fxe6rCy5UQke4wkdIKVqQ8S8l5Ujt3lq1EWRMCOHNG2s5L+MtJup+feom6XJEym4GrV9WJwV5aqUhxaB+RS2pHBKF3szgAwKIdf+Onk2nYf9mAn06mwVzs+Ac65mKB3X9dwZcHz2H3X1ec2oeS+yEix/iqHQBdx4qUZ7VuDaxcqUxFKiVF2e10wF9OXKKjpbbaqgThD4SGSmulXboEVK+uThz20FpFikP7iJw2ulM9fP1bCj4/cA6fHzgHwIhlf/yMuPAATO3fFL2uJ1qV2XQ4BdM3HEVKRskC2Y7uQ8n9EJHjWJHSClakPEtuOKFERSrOzjcqe7fTAX/5d0vtCote5kmxIkXkNS5m5pV7f2pGHh5dfgCbDlf+odmmwyl4dPmBUsmPo/tQcj9E5BwmUlrBipRnyYnUn3+6fs7//rvi7xsMQO3aQKdOrh1HQywVKbUrLHpYSyovr+RDDbXPl3z8y5e9as4ekaeYiwWmbzha7vfkwXTTNxytcGidvI/ytrB3H0ruh4icx6F9WsGKlGdFRQG1aklzm3791fkkZ8ECYNy4kq8NhvIbH8ydCxiNzh1Dg1iRcoAcm8kEVKumaiiIipJ+R4uLgStX1P/5EenM3pNpZao/1gSAlIw8JM3ZjpCA8i+xruUVubwPR/az92Qa2tePtLkdETmPiZRWyFWj/Hzpn7+/6/tkRapirVtLidTBg84lUv/7HzBpknT7iSeAzp2l7nw3Np6YNAkYNMjVaDVFMxUpPSRS8jA6NeeTyXx9gchIqSJ18SITKSIHXcyynbhY++tytsvHUmIfgP0xE5HjmEhpRWhoye3MzJILRFewIlWxVq2ADRucazgxYwbwwgvS7WefBWbOlC6S77lH6s6XkgJ8+y2wdCnw1VfAq69KF7Fewk8rFSl5aJ+WEymtzI+SRUdLidSFC0CzZmpHQ6Qr0aEBdm33TM+b0Tiu/Pfe31MyMfvbEy7tw5H92BszETnOe67s9M5oBEJCgGvXlEukWJGqmDMt0IWQEqiZM6WvX35Z+lquNBiNQJcu0u2+faUk6vhx4OOPgZEjlYpcdQFaq0hpeY6UVjr2yWJigKNH2bmPyAlt60UgLjwAqRl55c5NMgCIDQ/A2MQGMPqUX4FOvDkaH+/5x6V9OLKftvUiKn9iROQUNpvQEqXnScn7YSJVPrnhxOHDQEFB5dsLAUyeXJJEvf468OKLtodrhYUBU6ZIt6dNk4ZsegnNVKT0NrRPC9i5j8hpRh8DpvZvCkBKVKzJX0/t37TCBEiJfVS2H0CaI2XPfojIeUyktETpzn3yfji0r3wJCdLk/8JC4NixirctLpaaSvzvf9LX77wDPPVU5ccYNw6Ijwf++Qd4/31XI9YMzpFygFz5UftcybiWFJFLejWLw4IHb0VseOkhc7HhAVjw4K12rd2kxD4q2g8A3BwTgp63xNq1HyJyDof2aYmcSLEi5RkGg1SV2rZNmifVsmX525nNwOjR0nwngwH44ANg1Cj7jhEYCLz0EvDII8Arr0iPCw5W6hmow2yGf1aWdFvtKose2p9rbWgfK1JELuvVLA49msZi958XsXnnT0jq1A7tG0Q7VP2R97H3ZBouZuUhOlQahudoBenG/RgATP7sV5y4cA1bj1/EXY018tpD5IVYkdISJYf2yd3/rPdLZcnD+2w1nCgsBIYOlZIooxFYscL+JEo2ahRw001SBeCtt1wKVxOuXIGhuFi6rcRcPlfoqSKldtIpkxM6JlJELjH6GNCuXgRuixJo50QCJO+jff1IDGhVE+3rRzo9DM96P3e3qolRHesBAGZu/B1F5mKn9klElWMipSVKDu2z3gcTKdsqajiRnw/861/AJ59IawB9+inwwAOOH8NkkppSAMDs2UB6utPhasL1xEBERqrfiVBOpHJypH9apLWKFIf2EXm9x7o2QPUgE/68eA2r951ROxwir8VESkuUrEjJ+wgO9qqFYBUnV6QOHpTmQclycoABA4Avv5TW9PriC9fWgho8WGo1ffUq8MYbzu9HAwxy9UcLFZbQUMDPT7qt1aqU1ipSHNpH5PXCAkyY0P1mAMD/kk8gK69Q5YiIvBMTKS2R15Las0eat2M2O78vuephMrm+L2/WpIl0jjIzpWF327ZJSWjfvtI6UEFBwNdfA336uHYco1GaIwUAc+d69iLWbJae16pVrv8umM0wbNsGABB+fur/XhkMys+TUvJ8FRSUJFJ//aX++QJKzldKCrB1qzZiIiLFDWlXBzdFBeNKdgEWbv9L7XCIvBITKa1Yuxb46CPp9ldfAV27Sl3l1q51bl99+0q3r151bV/ebsOGktsTJ0rnKjpauoAODZWSqW7dlDnW3XcDbdsCOTnwee01ZfZZmbVrpZ99167AkCGu/14lJMA4axYAwOfXX7Xxe6XkPCmlz1e9elLbfAC47z71z9fatUBionS7sBC46y71YyIitzAZffBs78YAgA92nsT5q7kqR0TkfZhIacHatdJF1o1zo86dk+535CJH3teNF5XO7Mvbyeeq8IYhD/KaUi+8AHTsqNzxDAbLGlQ+77+PQHfPUZGf39mzpe935fdKiX0pTalEyh3n6/x51/elFDmmc+e0ExMRuVWPpjFoWy8C+UXFeOPb42qHQ+R1mEipzWwGnnyy5FNra/J9EybYN/xGyX15u4rOFSAlPe+8o/y56tYNuOsuGAoK0OiTT5Tdt7Wq9HulRCLl7edLizERkdsZDAa80LcJAGDtL+dw+JxC61QSEQAmUurbubPsJ+DWhADOnAFCQqShZhX9Cwmxb187dyr/PPTG3vPujnM1YwYAoM7WrcBxN31C6MjvlT3/tPx7pcQcKW8/X2r+vhORqlrUqoZ7WsUDAF799rjNzw+JyHFckFdtKSn2bZeX5/ljejN7z4E7ztUdd6C4Xz/4fPUVjNOnA599pvwxqtLvlRIVKW8/X2r+vhOR6p7u1RgbD6fip5PpaO5nQF+1AyLyEkyk1BYXZ992K1YAd9xR8TZ79kiLxyp1TG9m7zlw07kyT5sGw9dfw2fNGmkxYHk9K6XYG/fKlfb9Xg0ZotwxlaZEIuXt50vl33ciUlfNaoEY3bEeFmz7C+tP+2CSuRgmk9pREekfEym1deoE1KolTfgur95uMEjf//e/K18Pqm5d4L//rXxfnTopE7ue2Xve3XWuWrTA2U6dUHvHDqmpxddfK7v/Dh2kNcSys8v/vvz87r+/8t+rOnWAZ57R7u+VEolUVlbF39f7+ars9x0AIiP52kDkxcZ1qY9P9v2Di9mF+PTnsxjRsb7aIRHpHudIqc1oBObNk24bDKW/J389d659i+oquS9vp4FzdfyBByCMRmDjRuCHH5TbcWEhMHJkxUkU4D2/V67Okfrss9KLLXvj32FFMcmuXAGWLvVcTETkUaEBJjzRVUqe5n3/FzK5SC+Ry5hIacGgQcCaNUDNmqXvr1VLut/6Is+T+/J2Kp+r7Lg4FI8cKX3x3HO2KwWOyM8H/vUvaQiary8waZL0fKx52++VKxWpjz4CBg8GioqABx4APvnEe/8ObcVUuzaQlCTdHj0aePddz8dGRB5xf5taiAkUSM8pxIJtXKSXyFUc2qcVgwYBAwZIXbNSUqS5Cp06OfeptZL78nYqn6vi556D8eOPpeNv3gz07On8zrKzgYEDgeRkwN9fumju1w+YPVvR36uirVtx8Jtv0Kp3b/h27ar+75WcSKWnS9U4ewf+v/WW1BIcAMaMARYskJ7Lvfd679+hrZh8fKSke+5cYPx4qanG5MnqxUlEbmEy+uDuOsVYdNyID384iaHt6qBW9SC1wyLSLSZSWmI0Al26aG9f3k7Nc1WrFvDYY8CcOVJVKinJ9tCrimRkAH37Aj/+KM2NWr8euOsu6XsK/16JxEScy85Gy8RE9ZMoAIiIkM6ZENLwtNjYircXAj6zZgFTp0pfT54MvP56yXn39r9DWzHNmQMEBUmLRj/1FJCTI83fc+b3kYg065bqAnfUq449J9PxxrfHMXewws2OiKoQDu0jUtuzz0prDx04AKxd6/jjL1+WkqYffwSqVQO2bClJoqoCo1FKpoDK50kJgabLlsEoJ1HTp5dOoqoyg0Fa4+yVV6SvX3oJeP55ZYacEpFmGAzAs70awWAAvjh4Hr+euap2SES6xUSKSG01akjDqgCpAmA22//Y8+eBxEQpCatRA9i6tfL23N7InnlSxcXwefxxNFy3Tvp6zhwpWWASVdrzzwNvvindnjULmDiRyRSRl7klPgwDW0vzJWdsPAbBv3EipzCRItKCSZOkqsrvvwPLl9v3mJMnpfktR49KDQR27ABatXJrmJpVWSJVVAQMHw7j++9DGAwoWrBAShCofJMmAfPnS7fnzQMeeQQoLlY3JiJS1FNJjeDv64O9J9Ow+egFtcMh0iUmUkRaEB4uDfEDpLk7+fkVb//771IS9fffwE03Sc0DGjd2f5xaVVEilZ8vrf+0fDmEry/2T5oEMXq0Z+PTo0cfBRYvlhpRvP8+MGKElJASkVeIrxaIMZ1uAgC8+s3vKDTzwxIiRzGRItKKxx6TuqidPg188IHt7Q4eBDp3lhZXbdpUSqLq1fNYmJpkay2p7Gygf39g3TrA3x/mTz/FOS46a78RI4AVK6R5aB9/DAwZInVGJCKv8EiX+ogK8cPJy9lYsee02uEQ6Q4TKSKtCAoCXnxRuv1//1f+grq7dwNdu0qVl1tvBbZvB+LjPRunFpVXkcrIkNrJJydLnQw3boTo10+d+PRs8GCplb7JJC1efO+9Unt0ItK9EH9fTOxxMwBg3nd/ICOXH5QQOYLtz4m0ZPRoqYvcyZPSOkft25es91NYKK0TlZ0N3Hkn8PXX0pBAAiIjpf/37we2bQOaNAH69JGacFSrBnzzjdSEg9UU59xzj9RSf+BAYMMGaS2q61U+Ta2TRUQO+3eb2ljy4yn8cfEa3vn+D9zVOAYXs/IQHRqAtvUiYPRxvCGPuVhg78k0Rfbz08k07L9sQOTJNLRvEO3wfpSMxVv3w3PsPK9JpObPn4/XX38dKSkpuOWWWzB37lx04hAe0hs/P6kl90MP2W493b078MUXUpWFpJbxcsvuPXukip2vrzSfp0YNaaHjqtqEQ0m9eknJ+913S+f09tuBq1elzpGyWrWk5hSDBqkWJhE5xtfog+f6NMHIJfuwaOdJLNp50vK9uPAATO3fFL2axdm9v02HUzB9w1GkZJRUrl3fjxHL/vjZ4f24JxZv3Q/PsTO8YmjfJ598ggkTJuD555/HL7/8gk6dOqF37974559/1A6NyHGBgdL/ttrRjh7NJEq2di1w331AWlrp++WmCC++yCRKSXfdBXz7rfQ7evRo6SQKkObt3Xefc+uhEZFq8grLX3YjNSMPjy4/gE2HU+zaz6bDKXh0+YFSF7Fq7UdLsXjrfrQUi5L7cYRXJFJz5szB6NGj8Z///AdNmjTB3LlzUbt2bSxYsEDt0IgcYzZX3JbbYACeecaxtaa8ldkMPPmk7YTTYJCGSfJcKeuOO4DQ0PK/J/8sJkzgeSfSCXOxwMtfHS33e/Kr6/QNR2EurnitKXOxwPQNR1HeVp7ej5Zi8db9aCkWJffjKN0P7SsoKMD+/fvxrNw6+rqkpCTs2rWr3Mfk5+cj36q9dGZmJgCgsLAQhU7MoZAf48xj1cbY1WErdsP27fA9e9b2A4UAzpxB0datEImJ7gzRJq2cd2fOlVZid4ZWYjds3w7fixdtb2Djd9RW/Go/H6Kqbu/JtDKf4FsTAFIy8tDl9a0I9rd92ZidX6SZ/agZixACmVlGzP97FwzXF3zX0rlRaj96Pcd7T6ahff1Im9s5SveJ1OXLl2E2mxETE1Pq/piYGKSmppb7mFmzZmH69Oll7t+8eTOCgoKcjiU5Odnpx6qNsavjxthr7tiBNnY87uA33+BceV39PEjt8+7KuVI7dleoHburv6M3xp+Tk6NQZM5JT0/HE088gfXr1wMA7r77brz99tuoVq2azcdcuHAB//3vf7F582ZcvXoVnTt3xttvv42GDRtatsnPz8dTTz2FVatWITc3F926dcP8+fNRq1Ytdz8lIodczLKvC+eZ9FxFjqel/bgvFgNScq5pKB719qO1c2zv77u9dJ9IyeSMVCaEKHOfbMqUKZg0aZLl68zMTNSuXRtJSUkICwtz+NiFhYVITk5Gjx49YDKZHH68mhi7OmzFbggOBubMqfTxrXr3RksVK1JaOO/OnCutxO4MrcTu7O+orfjlEQFqGTJkCM6ePYtNmzYBAB5++GEMGzYMGzZsKHd7IQTuuecemEwmfPnllwgLC8OcOXPQvXt3HD16FMHX5y9OmDABGzZswOrVqxEZGYnJkyejX79+2L9/P4zsbEgaEh0aYNd2z/VpgqZxtq+RjqZkYubGY5rYj5qxFJmLsPenvWjbri18jb6qx+Ou/ej1HNv7+24v3SdSUVFRMBqNZapPFy9eLFOlkvn7+8Pf37/M/SaTyaULFFcfrybGro4ysXftKnU+O3eu/Lk/BgNQqxZ8u3ZVvc206ufdhXOleuwuUD12F39Hb4xfzedy7NgxbNq0CXv27EG7du0AAIsWLUL79u1x/PhxNGrUqMxj/vjjD+zZsweHDx/GLbfcAkDqGhsdHY1Vq1bhP//5DzIyMvDhhx/i448/Rvfu3QEAy5cvR+3atbFlyxb07NnTc0+SqBJt60UgLjwAqRl55c4vMQCIDQ/A6I71Kmwh3b5+JBb/eFIT+1EzlsLCQmQcF7izfqTl9U1L50ap/ej1HLetF2EzFmfovtmEn58fbrvttjLDRZKTk9GhQweVoiJyktEotY8GpAtSa/LXc+eqnkRpAs+VOrzovO/evRvh4eGWJAoA7rjjDoSHh1c4xxYAAgJKPtU0Go3w8/PDDz/8AADYv38/CgsLkZSUZNkmPj4ezZo1s7lfed+ZmZml/gEl83ed+efq4z39T2/x6jHmG+MtNhfh+d7ShwY3Xu7KXz/fuxGKzUUV7ldL+1E7Fp5j/Z7jG49RGd1XpABg0qRJGDZsGNq0aYP27dvj/fffxz///INHHnlE7dCIHDdoELBmjdSRzrqZQq1a0gUq1+gpwXOlDi8576mpqYiOji5zf3R0tM05to0bN0bdunUxZcoUvPfeewgODsacOXOQmpqKlJQUy379/PxQvXr1Uo+taO4uwPm7Mr3FC+gv5vLiHXmzAWtP+eBqQcllaLifwKCEYphP78fG0/btW0v7UTMWnmN9n2N75+96RSL173//G1euXMHLL7+MlJQUNGvWDBs3bkTdunXVDo3IOYMGAQMGADt3AikpQFwc0KmTLj7l9zieK3Vo+LxPmzat3ITE2r59+wCUnV8LVDzH1mQy4fPPP8fo0aMREREBo9GI7t27o3fv3pXGVdF+Ac7f1Vu8gP5irijePgCeKRb4+XQ6LmblIzrUH23qVq9wWFZ5lN7Pnr8u4fvd+3FX+9twR/0aDu1HjefEc+wd59je+btekUgBwLhx4zBu3Di1wyBSjtEIdOmidhT6wHOlDo2e9/Hjx2Pw4MEVbpOQkIBDhw7hwoULZb536dIlm3NsAeC2227DwYMHkZGRgYKCAtSoUQPt2rVDmzZSP8PY2FgUFBQgPT29VFXq4sWLFQ455/xdid7iBfQXs614TQA63mz7d9/u/Su4n/9v795jmrweN4A/RQooQtWJAoqAbIoI84I68Ybxgpd5i8sA5/A6Np0OnRo1W4wkZhPdvDsvW1Ccms05hBldVFTAKxe1zgsMjaCQiBp0VpSoKOf3hz/6XaUt1NH2Pfp8EhJ5e87bh9O6Z6ctr73faQHdVYHe77R4pTW218/ENX61LEpZ47quw2uzkSIiIgJeXISoefPmtY4LCwuDTqdDTk4OevToAQDIzs6GTqer0+/YajQaAC8uQHHmzBksWbIEwIuNllqtRlpaGiIjIwEApaWluHTpEpYvX/6qPxYRESmM9BebICIiehUdOnTA0KFDERsbi6ysLGRlZSE2NhYjRowwuGJfYGAgUlJS9N/v3r0bGRkZKCwsxB9//IHBgwdjzJgx+otLaDQaTJ06FXPnzsWRI0eg1Wrx8ccfIyQkRH8VPyIikh/fkSIiojfWzp07ERcXp98EjRo1CuvXrzcYU1BQAJ1Op/++tLQUc+bMwe3bt+Hl5YUJEyZg0aJFBnNWrVoFR0dHREZG6v9B3qSkJP4bUkRErxFupIiI6I3VrFkz7Nixw+wY8dK/lxUXF4e4uDizc1xcXLBu3TqsW7fuP2ckIiJl4kf7iIiIiIiILMSNFBERERERkYW4kSIiIiIiIrIQN1JEREREREQW4kaKiIiIiIjIQtxIERERERERWYiXP8f/Lm374MGDV5pfWVmJiooKPHjwAGq1uj6jWR2z2wez2wez24+p/NX/3X35EuP05nWTbHkB+TLLlheQL7NseQH5Mtsib127iRspAOXl5QAAHx8fOychInozlZeXQ6PR2DuGorCbiIjsq7ZuUgm+DIiqqircvHkTbm5uUKlUFs9/8OABfHx8UFJSAnd3dysktB5mtw9mtw9mtx9T+YUQKC8vh7e3Nxwc+Gnzf3vTukm2vIB8mWXLC8iXWba8gHyZbZG3rt3Ed6QAODg4oHXr1v/5PO7u7lI8AY1hdvtgdvtgdvsxlp/vRBn3pnaTbHkB+TLLlheQL7NseQH5Mls7b126iS//ERERERERWYgbKSIiIiIiIgtxI1UPnJ2dsXjxYjg7O9s7isWY3T6Y3T6Y3X5kzy8j2dZctryAfJllywvIl1m2vIB8mZWUlxebICIiIiIishDfkSIiIiIiIrIQN1JEREREREQW4kaKiIiIiIjIQtxIERERERERWYgbqTrasGED/P394eLigtDQUBw/ftzs+MzMTISGhsLFxQVt27bFpk2bbJT0f5YuXYru3bvDzc0NLVq0wJgxY1BQUGB2TkZGBlQqVY2vv//+20apX4iPj6+RwdPT0+wcJaw5APj5+RldwxkzZhgdb881P3bsGEaOHAlvb2+oVCqkpqYa3C6EQHx8PLy9vdGwYUP0798fly9frvW8ycnJCAoKgrOzM4KCgpCSkmLT7JWVlViwYAFCQkLg6uoKb29vTJgwATdv3jR7zqSkJKOPxePHj22aHwAmTZpUI0fPnj1rPa+91x6A0TVUqVT47rvvTJ7Tlmv/upCpl2TsI9l6SIbuka1zZOwZ2bpF9j7hRqoOdu3ahdmzZ+Prr7+GVqtF3759MWzYMBQXFxsdX1RUhOHDh6Nv377QarX46quvEBcXh+TkZJvmzszMxIwZM5CVlYW0tDQ8e/YMERERePToUa1zCwoKUFpaqv965513bJDYUMeOHQ0yXLx40eRYpaw5AOTm5hrkTktLAwB8+OGHZufZY80fPXqETp06Yf369UZvX758OVauXIn169cjNzcXnp6eGDx4MMrLy02e8/Tp04iKikJMTAz++usvxMTEIDIyEtnZ2TbLXlFRgXPnzmHRokU4d+4c9uzZgytXrmDUqFG1ntfd3d3gcSgtLYWLi0u9Zq8tf7WhQ4ca5Pjzzz/NnlMJaw+gxvpt2bIFKpUKH3zwgdnz2mrtXwey9ZKsfSRTD8nQPbJ1jow9I1u3SN8ngmrVo0cPMW3aNINjgYGBYuHChUbHz58/XwQGBhoc++yzz0TPnj2tlrEu7ty5IwCIzMxMk2PS09MFAPHPP//YLpgRixcvFp06darzeKWuuRBCzJo1SwQEBIiqqiqjtytlzQGIlJQU/fdVVVXC09NTJCQk6I89fvxYaDQasWnTJpPniYyMFEOHDjU4NmTIEBEdHV3vmau9nN2YnJwcAUDcuHHD5JitW7cKjUZTv+HqwFj+iRMnitGjR1t0HqWu/ejRo8WAAQPMjrHX2stK9l6SoY9k7yGld49snSNjz8jWLTL2Cd+RqsXTp09x9uxZREREGByPiIjAqVOnjM45ffp0jfFDhgzBmTNnUFlZabWstdHpdACAZs2a1Tq2S5cu8PLywsCBA5Genm7taEZdvXoV3t7e8Pf3R3R0NAoLC02OVeqaP336FDt27MCUKVOgUqnMjlXCmv9bUVERbt26ZbCuzs7OCA8PN/ncB0w/Fubm2IJOp4NKpUKTJk3Mjnv48CF8fX3RunVrjBgxAlqt1jYBjcjIyECLFi3Qrl07xMbG4s6dO2bHK3Htb9++jf3792Pq1Km1jlXS2ivZ69BLsvSRrD0kY/e8Dp0jS8/I2i1K7BNupGpRVlaG58+fo2XLlgbHW7ZsiVu3bhmdc+vWLaPjnz17hrKyMqtlNUcIgTlz5qBPnz4IDg42Oc7Lyws//vgjkpOTsWfPHrRv3x4DBw7EsWPHbJgWeO+99/Dzzz/j4MGD+Omnn3Dr1i306tULd+/eNTpeiWsOAKmpqbh//z4mTZpkcoxS1vxl1c9vS5771fMsnWNtjx8/xsKFC/HRRx/B3d3d5LjAwEAkJSVh7969+OWXX+Di4oLevXvj6tWrNkz7wrBhw7Bz504cPXoUK1asQG5uLgYMGIAnT56YnKPEtd+2bRvc3NwwduxYs+OUtPZKJ3svydJHMveQjN0je+fI0jMyd4sS+8Sx3s/4mnr5FR0hhNlXeYyNN3bcVmbOnIkLFy7gxIkTZse1b98e7du3138fFhaGkpISfP/99+jXr5+1Y+oNGzZM/+eQkBCEhYUhICAA27Ztw5w5c4zOUdqaA0BiYiKGDRsGb29vk2OUsuamWPrcf9U51lJZWYno6GhUVVVhw4YNZsf27NnT4Jdue/fuja5du2LdunVYu3attaMaiIqK0v85ODgY3bp1g6+vL/bv32+2RJS09gCwZcsWjB8/vtbPpitp7WUhay/J0kcy95DM3SNj58jUMzJ3ixL7hO9I1aJ58+Zo0KBBjV33nTt3auzOq3l6ehod7+joiLfeestqWU354osvsHfvXqSnp6N169YWz+/Zs6fdXxV2dXVFSEiIyRxKW3MAuHHjBg4fPoxPPvnE4rlKWPPqq1NZ8tyvnmfpHGuprKxEZGQkioqKkJaWZvZVQmMcHBzQvXt3uz8WwItXj319fc1mUdLaA8Dx48dRUFDwSn8HlLT2SiNzL8ncR7L0kKzdI2vnyN4zsnSLUvuEG6laODk5ITQ0VH/1m2ppaWno1auX0TlhYWE1xh86dAjdunWDWq22WtaXCSEwc+ZM7NmzB0ePHoW/v/8rnUer1cLLy6ue01nmyZMnyM/PN5lDKWv+b1u3bkWLFi3w/vvvWzxXCWvu7+8PT09Pg3V9+vQpMjMzTT73AdOPhbk51lBdblevXsXhw4df6X9khBA4f/683R8LALh79y5KSkrMZlHK2ldLTExEaGgoOnXqZPFcJa290sjYS69DH8nSQ7J2j4yd8zr0jCzdotg+scklLST366+/CrVaLRITE0VeXp6YPXu2cHV1FdevXxdCCLFw4UIRExOjH19YWCgaNWokvvzyS5GXlycSExOFWq0Wv//+u01zT58+XWg0GpGRkSFKS0v1XxUVFfoxL2dftWqVSElJEVeuXBGXLl0SCxcuFABEcnKyTbPPnTtXZGRkiMLCQpGVlSVGjBgh3NzcFL/m1Z4/fy7atGkjFixYUOM2Ja15eXm50Gq1QqvVCgBi5cqVQqvV6q84lJCQIDQajdizZ4+4ePGiGDdunPDy8hIPHjzQnyMmJsbgSmEnT54UDRo0EAkJCSI/P18kJCQIR0dHkZWVZbPslZWVYtSoUaJ169bi/PnzBs//J0+emMweHx8vDhw4IK5duya0Wq2YPHmycHR0FNnZ2fWavbb85eXlYu7cueLUqVOiqKhIpKeni7CwMNGqVSvFr301nU4nGjVqJDZu3Gj0HPZc+9eBbL0kYx/J2ENK7x7ZOkfGnpGtW2TvE26k6uiHH34Qvr6+wsnJSXTt2tXgkq0TJ04U4eHhBuMzMjJEly5dhJOTk/Dz8zP54FsTAKNfW7du1Y95OfuyZctEQECAcHFxEU2bNhV9+vQR+/fvt3n2qKgo4eXlJdRqtfD29hZjx44Vly9fNplbCGWsebWDBw8KAKKgoKDGbUpa8+rL3778NXHiRCHEi8vRLl68WHh6egpnZ2fRr18/cfHiRYNzhIeH68dX2717t2jfvr1Qq9UiMDDQKsVsLntRUZHJ5396errJ7LNnzxZt2rQRTk5OwsPDQ0RERIhTp07Ve/ba8ldUVIiIiAjh4eEh1Gq1aNOmjZg4caIoLi42OIcS177a5s2bRcOGDcX9+/eNnsOea/+6kKmXZOwjGXtI6d0jW+fI2DOydYvsfaIS4v9/E5KIiIiIiIjqhL8jRUREREREZCFupIiIiIiIiCzEjRQREREREZGFuJEiIiIiIiKyEDdSREREREREFuJGioiIiIiIyELcSBEREREREVmIGykiIiIiIiILcSNF9Ibw8/PD6tWr7R2DiIhIj91EMuNGisgKJk2ahDFjxgAA+vfvj9mzZ9vsvpOSktCkSZMax3Nzc/Hpp5/aLAcRESkLu4mofjnaOwAR1c3Tp0/h5OT0yvM9PDzqMQ0RERG7id5sfEeKyIomTZqEzMxMrFmzBiqVCiqVCtevXwcA5OXlYfjw4WjcuDFatmyJmJgYlJWV6ef2798fM2fOxJw5c9C8eXMMHjwYALBy5UqEhITA1dUVPj4++Pzzz/Hw4UMAQEZGBiZPngydTqe/v/j4eAA1Pz5RXFyM0aNHo3HjxnB3d0dkZCRu376tvz0+Ph6dO3fG9u3b4efnB41Gg+joaJSXl1t30YiIyKrYTUT1gxspIitas2YNwsLCEBsbi9LSUpSWlsLHxwelpaUIDw9H586dcebMGRw4cAC3b99GZGSkwfxt27bB0dERJ0+exObNmwEADg4OWLt2LS5duoRt27bh6NGjmD9/PgCgV69eWL16Ndzd3fX3N2/evBq5hBAYM2YM7t27h8zMTKSlpeHatWuIiooyGHft2jWkpqZi37592LdvHzIzM5GQkGCl1SIiIltgNxHVD360j8iKNBoNnJyc0KhRI3h6euqPb9y4EV27dsW3336rP7Zlyxb4+PjgypUraNeuHQDg7bffxvLlyw3O+e/PtPv7+2PJkiWYPn06NmzYACcnJ2g0GqhUKoP7e9nhw4dx4cIFFBUVwcfHBwCwfft2dOzYEbm5uejevTsAoKqqCklJSXBzcwMAxMTE4MiRI/jmm2/+28IQEZHdsJuI6gffkSKyg7NnzyI9PR2NGzfWfwUGBgJ48UpbtW7dutWYm56ejsGDB6NVq1Zwc3PDhAkTcPfuXTx69KjO95+fnw8fHx99UQFAUFAQmjRpgvz8fP0xPz8/fVEBgJeXF+7cuWPRz0pERHJgNxFZhu9IEdlBVVUVRo4ciWXLltW4zcvLS/9nV1dXg9tu3LiB4cOHY9q0aViyZAmaNWuGEydOYOrUqaisrKzz/QshoFKpaj2uVqsNblepVKiqqqrz/RARkTzYTUSW4UaKyMqcnJzw/Plzg2Ndu3ZFcnIy/Pz84OhY97+GZ86cwbNnz7BixQo4OLx4Q/m3336r9f5eFhQUhOLiYpSUlOhf+cvLy4NOp0OHDh3qnIeIiOTEbiL67/jRPiIr8/PzQ3Z2Nq5fv46ysjJUVVVhxowZuHfvHsaNG4ecnBwUFhbi0KFDmDJlitmiCQgIwLNnz7Bu3ToUFhZi+/bt2LRpU437e/jwIY4cOYKysjJUVFTUOM+gQYPw7rvvYvz48Th37hxycnIwYcIEhIeHG/3IBhERvV7YTUT/HTdSRFY2b948NGjQAEFBQfDw8EBxcTG8vb1x8uRJPH/+HEOGDEFwcDBmzZoFjUajfzXPmM6dO2PlypVYtmwZgoODsXPnTixdutRgTK9evTBt2jRERUXBw8Ojxi8EAy8+BpGamoqmTZuiX79+GDRoENq2bYtdu3bV+89PRETKw24i+u9UQghh7xBEREREREQy4TtSREREREREFuJGioiIiIiIyELcSBEREREREVmIGykiIiIiIiILcSNFRERERERkIW6kiIiIiIiILMSNFBERERERkYW4kSIiIiIiIrIQN1JEREREREQW4kaKiIiIiIjIQtxIERERERERWej/AFOWjcQmyoauAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "Learning Rate: 0.008588998889416569\n",
      "Beta1: 0.9024607116077724\n",
      "Beta2: 0.9925083779644893\n",
      "Number of Epochs: 5\n",
      "Batch Size: 128\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import GPyOpt\n",
    "import tensorflow.keras as K\n",
    "\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def preprocess_data(X, Y):\n",
    "    \"\"\"\n",
    "    Pre-processes the data for your model\n",
    "\n",
    "    Inputs:\n",
    "    X - numpy.ndarray (m, 32, 32, 3) containing the CIFAR 10 data, where\n",
    "        m is the number of data points\n",
    "    Y - numpy.ndarray (m,) containing the CIFAR 10 labels for X\n",
    "\n",
    "    Returns:\n",
    "    X_p - numpy.ndarray containing the preprocessed X\n",
    "    Y_p - numpy.ndarray containing the preprocessed Y\n",
    "    \"\"\"\n",
    "    X_p = K.applications.densenet.preprocess_input(X)\n",
    "    Y_p = K.utils.to_categorical(Y, 10)\n",
    "    return X_p, Y_p\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = K.datasets.cifar10.load_data()\n",
    "X_train, Y_train = preprocess_data(X_train, Y_train)\n",
    "X_test, Y_test = preprocess_data(X_test, Y_test)\n",
    "\n",
    "# Normalize pixel values\n",
    "inputs = K.Input(shape=(32, 32, 3))\n",
    "input_resized = K.layers.Lambda(lambda image: K.backend.resize_images(\n",
    "    image, 160/32, 160/32, \"channels_last\"))(inputs)\n",
    "\n",
    "# Define the base model model\n",
    "def create_model(learning_rate, beta1, beta2, num_epochs, batch_size):\n",
    "    base_model = K.applications.InceptionV3(include_top=False,\n",
    "                                            weights='imagenet',\n",
    "                                            input_tensor=input_resized,\n",
    "                                            input_shape=(160, 160, 3),\n",
    "                                            pooling='avg')\n",
    "\n",
    "    model = K.models.Sequential()\n",
    "    model.add(base_model)\n",
    "\n",
    "    model.add(K.layers.Flatten())\n",
    "\n",
    "    # model.add(K.layers.Dense(256, activation=('relu')))\n",
    "    model.add(K.layers.Dense(256))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Activation('relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "\n",
    "    # model.add(K.layers.Dense(128, activation=('relu')))\n",
    "    model.add(K.layers.Dense(128))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Activation('relu'))\n",
    "    model.add(K.layers.Dropout(0.35))\n",
    "\n",
    "    # model.add(K.layers.Dense(64, activation=('relu')))\n",
    "    model.add(K.layers.Dense(64))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Activation('relu'))\n",
    "    model.add(K.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(K.layers.Dense(10, activation=('softmax')))\n",
    "\n",
    "    optimizer = K.optimizers.Adam(lr=learning_rate, beta_1=beta1, beta_2=beta2)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_model(params):\n",
    "    learning_rate = params[0, 0]\n",
    "    beta1 = params[0, 1]\n",
    "    beta2 = params[0, 2]\n",
    "    num_epochs = int(params[0, 3])\n",
    "    batch_size = int(params[0, 4])\n",
    "\n",
    "    model = create_model(learning_rate, beta1, beta2, num_epochs, batch_size)\n",
    "\n",
    "    # Define checkpoint and early stopping callbacks\n",
    "    ckpt_path = os.path.expanduser(\"/Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/ckpt_lr_{}_beta1_{}_beta2_{}_epochs_{}_batch_{}.h5\".format(\n",
    "        learning_rate.round(5),\n",
    "        beta1.round(4),\n",
    "        beta2.round(4),\n",
    "        num_epochs,\n",
    "        batch_size,\n",
    "        ))\n",
    "    checkpoint = ModelCheckpoint(ckpt_path,\n",
    "                                 monitor='val_accuracy',\n",
    "                                 save_best_only=True,\n",
    "                                 mode='max',\n",
    "                                 verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "                                   patience=5,\n",
    "                                   mode='max',\n",
    "                                   verbose=1)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, Y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        callbacks=[checkpoint, early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Get the best accuracy from the training\n",
    "    best_accuracy = max(history.history['val_accuracy'])\n",
    "\n",
    "    return best_accuracy\n",
    "\n",
    "# Define the bounds of the hyperparameters\n",
    "bounds = [\n",
    "    {'name': 'learning_rate', 'type': 'continuous', 'domain': (1e-6, 1e-2)},\n",
    "    {'name': 'beta1', 'type': 'continuous', 'domain': (0.85, 0.95)},\n",
    "    {'name': 'beta2', 'type': 'continuous', 'domain': (0.99, 0.999)},\n",
    "    {'name': 'num_epochs', 'type': 'discrete', 'domain': (5, 10, 15)},\n",
    "    {'name': 'batch_size', 'type': 'discrete', 'domain': (32, 64, 128)},\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "opt = GPyOpt.methods.BayesianOptimization(f=evaluate_model,\n",
    "                                          domain=bounds,\n",
    "                                          maximize=True)\n",
    "report_file_path = os.path.expanduser(\"/Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/bayes_opt.txt\")\n",
    "opt.run_optimization(max_iter=30, report_file=\"/Users/ezalta/Documents/GitHub/atlas-machine_learning/unsupervised_learning//hyperparameter_tuning/bayes_opt.txt\")\n",
    "\n",
    "# Plot the convergence\n",
    "opt.plot_convergence()\n",
    "\n",
    "# Show the best hyperparameters\n",
    "best_hyperparams = opt.X[np.argmax(opt.Y)]\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(\"Learning Rate:\", best_hyperparams[0])\n",
    "print(\"Beta1:\", best_hyperparams[1])\n",
    "print(\"Beta2:\", best_hyperparams[2])\n",
    "print(\"Number of Epochs:\", int(best_hyperparams[3]))\n",
    "print(\"Batch Size:\", int(best_hyperparams[4]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
