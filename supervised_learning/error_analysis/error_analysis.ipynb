{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0 - create_confusion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 0 - create_confusion.py\n",
    "def create_confusion_matrix(labels, logits):\n",
    "    \"\"\"\n",
    "    Creates a confusion matrix:\n",
    "\n",
    "    Inputs:\n",
    "    labels -  one-hot numpy.ndarray of shape (m, classes) containing the\n",
    "              correct labels for each data point\n",
    "        m - number of data points\n",
    "        classes - number of classes\n",
    "    logits - one-hot numpy.ndarray (m, classes) containing predicted labels\n",
    "\n",
    "    Returns:\n",
    "    Confusion numpy.ndarray of shape (classes, classes) with\n",
    "    row indices representing the correct labels and\n",
    "    column indices representing the predicted labels\n",
    "    \"\"\"\n",
    "    return np.matmul(labels.T, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4701.    0.   36.   17.   12.   81.   38.   11.   35.    1.]\n",
      " [   0. 5494.   36.   21.    3.   38.    7.   13.   59.    7.]\n",
      " [  64.   93. 4188.  103.  108.   17.  162.   80.  132.   21.]\n",
      " [  30.   48.  171. 4310.    2.  252.   22.   86.  128.   52.]\n",
      " [  17.   27.   35.    0. 4338.   11.   84.    9.   27.  311.]\n",
      " [  89.   57.   45.  235.   70. 3631.  123.   33.  163.   60.]\n",
      " [  47.   32.   87.    1.   64.   83. 4607.    0.   29.    1.]\n",
      " [  26.   95.   75.    7.   58.   18.    1. 4682.   13.  200.]\n",
      " [  31.  153.   82.  174.   27.  179.   64.    7. 4003.  122.]\n",
      " [  48.   37.   39.   71.  220.   49.    8.  244.   46. 4226.]]\n"
     ]
    }
   ],
   "source": [
    "# 0-main.py\n",
    "if __name__ == '__main__':\n",
    "    lib = np.load('labels_logits.npz')\n",
    "    labels = lib['labels']\n",
    "    logits = lib['logits']\n",
    "\n",
    "    np.set_printoptions(suppress=True)\n",
    "    confusion = create_confusion_matrix(labels, logits)\n",
    "    print(confusion)\n",
    "    np.savez_compressed('confusion.npz', confusion=confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - sensitivity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 - 1-sensitivity.py\n",
    "#!/usr/bin/env python3\n",
    "def sensitivity(confusion):\n",
    "    \"\"\"\n",
    "    Calculates the sensitivity for each class in a confusion matrix\n",
    "\n",
    "    Inputs:\n",
    "    confusion - confusion numpy.ndarray of shape (classes, classes) where\n",
    "        row indices represent the correct labels and\n",
    "        column indices represent the predicted labels\n",
    "        classes - the number of classes\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray of shape (classes,) containing the sensitivity of each class\n",
    "    \"\"\"\n",
    "    return np.diagonal(confusion) / np.sum(confusion, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95316302 0.96759422 0.84299517 0.84493237 0.89277629 0.80581447\n",
      " 0.93051909 0.9047343  0.82672449 0.84723336]\n"
     ]
    }
   ],
   "source": [
    "# 1-main.py\n",
    "if __name__ == '__main__':\n",
    "    confusion = np.load('confusion.npz')['confusion']\n",
    "\n",
    "    np.set_printoptions(suppress=True)\n",
    "    print(sensitivity(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - precision.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 - 2-precision.py\n",
    "def precision(confusion):\n",
    "    \"\"\"\n",
    "    Calculates the Precision for each class in a confusion matrix\n",
    "\n",
    "    Inputs:\n",
    "    confusion - confusion numpy.ndarray of shape (classes, classes) where\n",
    "        row indices represent the correct labels and\n",
    "        column indices represent the predicted labels\n",
    "        classes - the number of classes\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray of shape (classes,) containing the precision of each class\n",
    "    \"\"\"\n",
    "    return np.diagonal(confusion) / np.sum(confusion, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93033841 0.91020543 0.87359199 0.87264628 0.88494492 0.83298922\n",
      " 0.90050821 0.90648596 0.86364617 0.84503099]\n"
     ]
    }
   ],
   "source": [
    "# 2-main.py\n",
    "if __name__ == '__main__':\n",
    "    confusion = np.load('confusion.npz')['confusion']\n",
    "\n",
    "    np.set_printoptions(suppress=True)\n",
    "    print(precision(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - specificity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 - 3-specificity.py\n",
    "def specificity(confusion):\n",
    "    \"\"\"\n",
    "    Calculates the specificity for each class in a confusion matrix\n",
    "\n",
    "    Inputs:\n",
    "    confusion - confusion numpy.ndarray of shape (classes, classes) where\n",
    "        row indices represent the correct labels and\n",
    "        column indices represent the predicted labels\n",
    "        classes - the number of classes\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray of shape (classes,) containing the specificity of each class\n",
    "    \"\"\"\n",
    "\n",
    "    all_instances = np.sum(confusion)\n",
    "    true_positives = np.diag(confusion)\n",
    "    predicted_positives = np.sum(confusion, axis=0)\n",
    "    positives = np.sum(confusion, axis = 1)\n",
    "\n",
    "    true_negatives = (all_instances - predicted_positives -\n",
    "                      positives + true_positives)\n",
    "\n",
    "    number_negatives = (all_instances - positives)\n",
    "\n",
    "    true_negative_ratio = true_negatives / number_negatives\n",
    "\n",
    "    return true_negative_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99218958 0.98777131 0.9865429  0.98599078 0.98750582 0.98399789\n",
      " 0.98870119 0.98922476 0.98600469 0.98278237]\n"
     ]
    }
   ],
   "source": [
    "# 3-main.py\n",
    "if __name__ == '__main__':\n",
    "    confusion = np.load('confusion.npz')['confusion']\n",
    "\n",
    "    np.set_printoptions(suppress=True)\n",
    "    print(specificity(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - f1_score.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4 - 4-f1_score.py\n",
    "def f1_score(confusion):\n",
    "    \"\"\"\n",
    "    Calculates the F1 score of a confusion matrix\n",
    "\n",
    "    Inputs:\n",
    "    confusion - confusion numpy.ndarray of shape (classes, classes) where\n",
    "        row indices represent the correct labels and\n",
    "        column indices represent the predicted labels\n",
    "        classes - the number of classes\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray of shape (classes,) containing the F1 score of each class\n",
    "    \"\"\"\n",
    "\n",
    "    prec = precision(confusion)\n",
    "    sens = sensitivity(confusion)\n",
    "\n",
    "    f1 = 2 * (prec * sens) / (prec + sens)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94161242 0.93802288 0.8580209  0.85856574 0.88884336 0.81917654\n",
      " 0.91526771 0.90560928 0.8447821  0.84613074]\n"
     ]
    }
   ],
   "source": [
    "# 4-main.py\n",
    "if __name__ == '__main__':\n",
    "    confusion = np.load('confusion.npz')['confusion']\n",
    "\n",
    "    np.set_printoptions(suppress=True)\n",
    "    print(f1_score(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
